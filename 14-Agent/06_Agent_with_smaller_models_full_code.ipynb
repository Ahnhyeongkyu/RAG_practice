{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색도구: Tavily Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
    "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
    "search = TavilySearchResults(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 가 사용할 도구 목록 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools 리스트에 search 도구를 추가합니다.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent with smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_log_to_messages\n",
    "from langchain.agents.output_parsers import (\n",
    "    ReActJsonSingleInputOutputParser,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "local_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:3000\",\n",
    "    api_key=\"lm-studio\",\n",
    "    model=\"cognitivecomputations/dolphin-2.9-llama3-8b-gguf\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "llm_with_tools = local_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "chat_model_with_stop = local_llm.bind(stop=[\"Observation\", \"\\nObservation\", \"\\n관측\"])\n",
    "\n",
    "# Inspiration taken from hub.pull(\"hwchase17/react-json\")\n",
    "system_message = f\"\"\"Answer the following questions as best you can.\n",
    "You can answer directly if the user is greeting you or similar.\n",
    "Otherise, you have access to the following tools:\n",
    "\n",
    "{render_text_description_and_args(tools).replace('{', '{{').replace('}', '}}')}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use)\n",
    "and a `action_input` key (with the input to the tool going here).\n",
    "The only values that should be in the \"action\" field are: {[t.name for t in tools]}\n",
    "The $JSON_BLOB should only contain a SINGLE action, \n",
    "do NOT return a list of multiple actions.\n",
    "Here is an example of a valid $JSON_BLOB:\n",
    "```\n",
    "{{{{\n",
    "    \"action\": $TOOL_NAME,\n",
    "    \"action_input\": $INPUT\n",
    "}}}}\n",
    "```\n",
    "The $JSON_BLOB must always be enclosed with triple backticks!\n",
    "\n",
    "ALWAYS use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action... \n",
    "(this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer` when responding.'\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            system_message,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]):\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_messages(x[\"intermediate_steps\"]),\n",
    "        \"chat_history\": lambda x: (\n",
    "            _format_chat_history(x[\"chat_history\"]) if x.get(\n",
    "                \"chat_history\") else []\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | chat_model_with_stop\n",
    "    | ReActJsonSingleInputOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# Add typing for input\n",
    "class AgentInput(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[Tuple[str, str]] = Field(\n",
    "        ..., extra={\"widget\": {\"type\": \"chat\", \"input\": \"input\", \"output\": \"output\"}}\n",
    "    )\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ").with_types(input_type=AgentInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 요청 후 질문에 대한 답변을 출력합니다.\n",
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"판교 제로원에이아이 전화번호를 웹 검색하여 결과를 알려주세요.\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "print(f'답변: {response[\"output\"]}')\n",
    "# API 연결 문제로 실행 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "\n",
    "def format_search_result(search_result):\n",
    "    return \" \".join([r[\"content\"] for r in search_result])\n",
    "\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = (\n",
    "    agent_executor\n",
    "    | itemgetter(\"output\")\n",
    "    | ReActJsonSingleInputOutputParser()\n",
    "    | tool_executor\n",
    "    | format_search_result\n",
    ")\n",
    "\n",
    "search_agent_parallel = RunnableParallel(\n",
    "    context=search_agent, question=itemgetter(\"input\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent_parallel.invoke(\n",
    "    {\n",
    "        \"input\": \"판교 제로원에이아이 전화번호 웹 검색하여 알려줘.\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "# API 연결문제로 실행 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful AI Assistant. You must answer the question based on the context.\\n#Context: {context}\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "eeve = ChatOllama(\n",
    "    model=\"EEVE-Korean-10.8B:long\",\n",
    "    temperature=0,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(question=itemgetter(\"question\"),\n",
    "                     context=itemgetter(\"context\"))\n",
    "    | prompt\n",
    "    | eeve\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = search_agent_parallel | chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"판교 제로원에이아이 전화번호 검색하여 알려주세요\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "# API 연결문제로 실행 실패"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
