{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff Documents Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchainhub langchain_openai langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert summarizer. Please summarize the following sentence.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='Please summarize the sentence according to the following request.\\nREQUEST:\\n1. Summarize the main points in bullet points in Korean.2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.3. Use various emojis to make the summary more interesting.\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert summarizer. Please summarize the following sentence.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Please summarize the sentence according to the following request.\"\n",
    "            \"\\nREQUEST:\\n\"\n",
    "            \"1. Summarize the main points in bullet points in Korean.\"\n",
    "            \"2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\"\n",
    "            \"3. Use various emojis to make the summary more interesting.\"\n",
    "            \"\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 1\n",
      "\n",
      "[ë©”íƒ€ë°ì´í„°]\n",
      "\n",
      "{'source': 'data/news.txt'}\n",
      "\n",
      "========= [ì•žë¶€ë¶„] ë¯¸ë¦¬ë³´ê¸° =========\n",
      "\n",
      "ì œëª©: \n",
      "AI2, ìƒì—… í™œìš©ê¹Œì§€ ìžìœ ë¡œìš´ 'ì§„ì§œ' ì˜¤í”ˆ ì†ŒìŠ¤ LLM 'ì˜¬ëª¨' ì¶œì‹œ\n",
      "\n",
      "ë‚´ìš©:\n",
      "ì•¨ëŸ°AIì—°êµ¬ì†Œ(AI2)ê°€ ì™„ì „í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM) 'ì˜¬ëª¨(OLMo)â€™ë¥¼ ì¶œì‹œí–ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘, í•™ìŠµ, ë°°í¬ì˜ ì „ ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ê³µê°œí•œ ë°ë‹¤ ìƒì—…ì  ì‚¬ìš©ê¹Œì§€ í—ˆìš©í•œ ì§„ì •í•œ ì˜ë¯¸ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì´ë¼ëŠ” í‰ê°€ë‹¤.\n",
      "ë²¤ì²˜ë¹„íŠ¸ëŠ” 1ì¼(í˜„ì§€ì‹œê°„) ë¹„ì˜ë¦¬ ë¯¼ê°„ AI ì—°êµ¬ê¸°ê´€ì¸ AI2ê°€ â€˜ìµœì´ˆì˜ ì§„ì •í•œ ì˜¤í”ˆ ì†ŒìŠ¤ LLM ë° í”„ë ˆìž„ì›Œí¬â€™ë¼ê³  ì†Œê°œí•œ â€˜ì˜¬ëª¨â€™ë¥¼ ì¶œì‹œí–ˆë‹¤ê³  ë³´ë„í–ˆë‹¤. \n",
      "ì´ì— ë”°ë¥´ë©´ ì˜¬ëª¨ëŠ” ëª¨ë¸ ì½”ë“œì™€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¿ë§Œ ì•„ë‹ˆë¼ í›ˆë ¨ ì½”ë“œ, í›ˆë ¨ ë°ì´í„°, ê´€ë ¨ íˆ´í‚· ë° í‰ê°€ íˆ´í‚·ë„ ì œê³µí•œë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì–´ë–»ê²Œ êµ¬ì¶•ë˜ì—ˆëŠ”ì§€ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„, LLMì˜ ìž‘ë™ ë°©ì‹ê³¼ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì›ë¦¬ë¥¼ ë” ìž˜ ì´í•´í•  ìˆ˜ ìžˆë‹¤. \n",
      "ì˜¬ëª¨ í”„ë ˆìž„ì›Œí¬ëŠ” 70ì–µ ë§¤ê°œë³€ìˆ˜ì˜ â€˜ì˜¬ëª¨ 7Bâ€™ ë“± 4ê°€ì§€ ë³€í˜• ëª¨ë¸ê³¼ 10ì–µ ë§¤ê°œë³€ìˆ˜ì˜ â€˜ì˜¬ëª¨ 1Bâ€™ ëª¨ë¸ì„ ì œê³µí•œë‹¤. ëª¨ë¸ë“¤ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•´ \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/news.txt\")\n",
    "docs = loader.load()\n",
    "print(f\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\\n\")\n",
    "print(\"[ë©”íƒ€ë°ì´í„°]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [ì•žë¶€ë¶„] ë¯¸ë¦¬ë³´ê¸° =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ AI2ê°€ 'ì˜¬ëª¨(OLMo)'ë¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ LLM ì¶œì‹œ\n",
      "ðŸ” ë°ì´í„° ìˆ˜ì§‘, í•™ìŠµ, ë°°í¬ íˆ¬ëª…í•˜ê²Œ ê³µê°œ\n",
      "ðŸ”“ ìƒì—…ì  ì‚¬ìš© í—ˆìš©\n",
      "ðŸ”§ ì˜¬ëª¨ í”„ë ˆìž„ì›Œí¬ ë‹¤ì–‘í•œ ëª¨ë¸ ì œê³µ\n",
      "ðŸ“ˆ ì„±ëŠ¥ ìš°ìˆ˜, ë‹¤ì–‘í•œ ì–¸ì–´ì— ì œì•½\n",
      "ðŸŒ ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ë°˜ AI ëª¨ë¸ì— ëŒ€í•œ ì´í•´ ì´‰ì§„\n",
      "ðŸ”— ê¹ƒí—ˆë¸Œ ë° í—ˆê¹…íŽ˜ì´ìŠ¤ì—ì„œ ë¬´ë£Œë¡œ ì´ìš© ê°€ëŠ¥"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class MyCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    temperature=0.01,\n",
    "    callbacks=[MyCallbackHandler()],\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "answer = chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
