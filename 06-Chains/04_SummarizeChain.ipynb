{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the concept of building autonomous agents powered by large language models (LLMs). It explores the components of such agents, including planning, memory, and tool use. The article provides case studies and examples of proof-of-concept demos, highlighting the challenges and limitations of LLM-powered agents. It also includes citations and references for further reading.The article discusses the concept of building autonomous agents powered by large language models (LLMs). It explores the components of such agents, including planning, memory, and tool use. The article provides case studies and examples of proof-of-concept demos, highlighting the challenges and limitations of LLM-powered agents. It also includes citations and references for further reading.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "# 웹 기반 문서 로더를 초기화합니다.\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "\n",
    "# 문서를 로드합니다.\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "# OpenAI의 Chat 모델을 초기화합니다. 여기서는 온도를 0으로 설정하고 모델 이름을 지정합니다.\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-16k\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "# 요약 체인을 로드합니다. 체인 타입을 'stuff'로 지정합니다.\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# 문서에 대해 요약 체인을 실행합니다.\n",
    "answer = chain.invoke({\"input_documents\": docs})\n",
    "print(answer[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법1. stuff방법1. stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 먼저, PromptTemplate를 사용하여 요약문 작성을 위한 프롬프트를 정의합니다.\n",
    "2. 그 다음, LLMChain을 사용하여 지정된 모델(gpt-3.5-turbo-16k)과 온도 설정(0)을 사용하는 언어 모델 체인을 생성합니다.\n",
    "3. 이 체인은 입력된 텍스트에 대한 요약문을 생성하는 데 사용됩니다.\n",
    "4. 마지막으로, StuffDocumentsChain을 사용하여 문서들을 결합하고, 이를 LLMChain을 통해 요약합니다.\n",
    "5. 이 과정은 loader.load()로 로드된 문서들에 대해 실행되며, 결과는 실시간 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UserK\\miniforge3\\envs\\rag\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 LLM을 사용한 자율 에이전트 시스템은 LLM을 에이전트의 뇌로 사용하고 계획, 메모리, 도구 사용과 같은 여러 구성 요소로 보완됩니다.\n",
      "📝 계획 구성 요소는 큰 작업을 작은 하위 목표로 분해하고 에이전트가 과거 행동을 자가 비판하고 반영하여 최종 결과의 품질을 향상시킵니다.\n",
      "🧠 메모리 구성 요소는 감각 메모리, 단기 메모리, 장기 메모리로 구성되며, 외부 벡터 저장소와 빠른 검색을 통해 정보를 보존하고 검색할 수 있습니다.\n",
      "🛠️ 도구 사용 구성 요소는 외부 API를 호출하여 모델 가중치에 없는 추가 정보를 얻을 수 있습니다.\n",
      "🔍 이러한 구성 요소를 사용하여 LLM을 기반으로 한 에이전트를 구축하는 것은 재미있는 개념이지만, 제한된 컨텍스트 길이, 계획 및 작업 분해의 어려움, 자연어 인터페이스의 신뢰성 등의 제한 사항이 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "# prompt_template = \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "# REQUEST:\n",
    "# 1. Summarize the main points in bullet points in KOREAN.\n",
    "# 2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
    "# 3. Use various emojis to make the summary more interesting.\n",
    "# 4. Translate the summary into Korean if it is written in English.\n",
    "# 5. DO NOT translate any technical terms.\n",
    "# 6. DO NOT include any unnecessary information.\n",
    "# CONTEXT:\n",
    "# {context}\n",
    "\n",
    "# SUMMARY:\"\n",
    "# \"\"\"\n",
    "# prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 원격 저장소에서 프롬프트를 가져오는 경우\n",
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "\n",
    "# LLM 체인 정의\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-16k\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# LLMChain 정의\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# StuffDocumentsChain 정의\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"context\")\n",
    "\n",
    "docs = loader.load()\n",
    "response = stuff_chain.invoke({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법2. Map-Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ChatOpenAI 인스턴스를 생성하고, 이를 사용하여 문서 집합에 대한 주요 테마를 식별하는 맵(map) 작업을 정의합니다.\n",
    "2. 맵 작업은 map_template을 사용하여 정의되며, 이 템플릿은 문서 집합을 입력으로 받아 주요 테마를 식별하도록 요청합니다.\n",
    "3. PromptTemplate.from_template 메서드를 사용하여 map_template에서 프롬프트 템플릿을 생성하고, LLMChain을 사용하여 맵 작업을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['docs'], metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'map-prompt', 'lc_hub_commit_hash': '5325a713fc858810667d1d1dde32ccc2e93433b8706831560e75360b4993e95f'}, template='You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\\nPlease provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format. \\nThe summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format. \\nPlease ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition. \\nThe length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\\n\\nGIVEN DOCUMENTS:\\n{docs}\\n\\nFORMAT:\\n1. main theme 1\\n2. main theme 2\\n3. main theme 3\\n...\\n\\nCAUTION:\\n- DO NOT list more than 5 main themes.\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# # map-prompt 를 직접 정의하는 경우 다음의 예시를 참고하세요.\n",
    "# map_template = \"\"\"The following is a set of documents\n",
    "# {docs}\n",
    "# Based on this list of docs, please identify the main themes\n",
    "# Helpful Answer:\"\"\"\n",
    "# map_prompt = PromptTemplate.from_template(map_template)\n",
    "\n",
    "# langchain 허브에서 'rlm/map-prompt'를 가져옵니다.\n",
    "map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "map_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMChain 인스턴스를 생성하며, 이때 LLM과 프롬프트로 'map_prompt'를 사용합니다.\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-prompt 를 직접 정의하는 경우 다음의 예시를 참고하세요.\n",
    "# reduce_template = \"\"\"The following is set of summaries:\n",
    "# {docs}\n",
    "# Take these and distill it into a final, consolidated summary of the main themes.\n",
    "# Helpful Answer:\"\"\"\n",
    "# reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['doc_summaries'], metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'reduce-prompt-korean', 'lc_hub_commit_hash': '01613c7c2988c1e28d025507398b6c4aa4484e4450186e377b8e578bd22077ab'}, template='You are a helpful expert in summary writing.\\nYou are given numbered lists of summaries.\\nExtract top 10 most important insights from the summaries.\\nThen, write a summary of the insights in KOREAN.\\n\\nLIST OF SUMMARIES:\\n{doc_summaries}\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt hub에서도 얻을 수 있음을 위에서 언급했듯이\n",
    "reduce_prompt = hub.pull(\"teddynote/reduce-prompt-korean\")\n",
    "reduce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "# 연쇄 실행\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# 문서 리스트를 받아 하나의 문자열로 결합한 후 LLMChain에 전달\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# 매핑된 문서들을 결합하고 반복적으로 축소\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # 최종적으로 호출되는 체인입니다.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # `StuffDocumentsChain`의 컨텍스트를 초과하는 문서들을 처리\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # 문서들을 그룹화할 최대 토큰 수.\n",
    "    token_max=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서들을 매핑하여 체인을 거친 후 결과를 결합하는 과정\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # 매핑 체인\n",
    "    llm_chain=map_chain,\n",
    "    # 리듀스 체인\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # llm_chain에서 문서들을 넣을 변수 이름\n",
    "    document_variable_name=\"docs\",\n",
    "    # 매핑 단계의 결과를 출력에 포함시킴\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "# 문자를 기준으로 텍스트를 분할하는 객체 생성\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# 문서들을 분할\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The document discusses LLM powered autonomous agents, focusing on three main components: planning, memory, and tool use. \n",
      "2. Under planning, the document covers task decomposition and self-reflection as key aspects of agent systems. \n",
      "3. Memory is explored through different types and the use of Maximum Inner Product Search (MIPS) for efficient retrieval. \n",
      "4. Tool use is exemplified through case studies such as the Scientific Discovery Agent and Generative Agents Simulation, along with proof-of-concept examples. \n",
      "5. The document also highlights challenges faced by autonomous agents and provides citations and references for further reading.1. LLM (large language model) can serve as the core controller for building autonomous agents, showcasing potential beyond generating content like stories and essays.\n",
      "2. In an LLM-powered agent system, key components include planning, which involves breaking down tasks into subgoals for efficient handling, and memory, which allows for self-reflection and refinement of past actions to improve future results.1. Memory plays a crucial role in machine learning, with short-term memory being utilized for in-context learning and long-term memory allowing the agent to retain and recall vast amounts of information over extended periods.\n",
      "2. Tool use involves the agent calling external APIs to access additional information not present in the model weights, such as current information, code execution capability, and proprietary information sources.1. Planning is a crucial component of a LLM-powered autonomous agent system, as it involves breaking down complex tasks into smaller, manageable steps.\n",
      "2. Task decomposition, using techniques like Chain of Thought (CoT), enhances model performance by prompting the agent to think step by step and decompose difficult tasks into simpler components. This approach sheds light on the model's thinking process and improves overall task execution.1. Tree of Thoughts (ToT) extends the CoT model by exploring multiple reasoning possibilities at each step, creating a tree structure through problem decomposition and generating multiple thoughts per step.\n",
      "2. The search process in ToT can be conducted using BFS or DFS, with each state evaluated by a classifier or majority vote.\n",
      "3. Task decomposition in ToT can be achieved through LLM with simple prompting, task-specific instructions, or human inputs.\n",
      "4. ToT allows for a more comprehensive and diverse exploration of problem-solving paths, enhancing the overall reasoning process.\n",
      "5. The model offers flexibility in how tasks are decomposed and how different thoughts are generated, providing a versatile approach to problem-solving.1. LLM+P approach involves using an external classical planner for long-horizon planning, utilizing PDDL as an interface to describe the planning problem. The process includes translating the problem into PDDL, generating a PDDL plan with a classical planner, and translating the plan back into natural language.\n",
      "2. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve by learning from past actions and correcting mistakes, particularly in real-world tasks where trial and error are common.1. ReAct integrates reasoning and acting within LLM by expanding the action space to include task-specific discrete actions and language prompts.\n",
      "2. The ReAct prompt template guides LLM through explicit steps for thinking, acting, and observing, enabling the generation of reasoning traces in natural language.\n",
      "3. This approach allows LLM to interact with the environment, such as using the Wikipedia search API, while also prompting the generation of natural language reasoning traces.1. ReAct outperforms Act-only baseline in both knowledge-intensive and decision-making tasks by incorporating self-reflection and dynamic memory capabilities.\n",
      "2. Reflexion framework enhances agents' reasoning skills by equipping them with self-reflection and dynamic memory capabilities.\n",
      "3. Reflexion framework utilizes a standard RL setup with a binary reward model and task-specific action space augmented with language for complex reasoning steps.\n",
      "4. Agents using Reflexion framework compute heuristics after each action and may choose to reset the environment based on self-reflection results.\n",
      "5. The experiments on knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop) demonstrate the effectiveness of ReAct over the Act-only baseline.1. The Reflexion framework is illustrated as a tool for improving trajectory planning efficiency by identifying inefficiencies and hallucinations.\n",
      "2. Inefficient planning is characterized by trajectories that take too long without success, while hallucination involves consecutive identical actions leading to the same observation.\n",
      "3. Self-reflection is facilitated by presenting failed trajectory examples to the LLM and providing ideal reflections for guiding future plan adjustments.\n",
      "4. The agent's working memory stores up to three reflections as context for querying the LLM.\n",
      "5. The heuristic function plays a crucial role in determining when to stop inefficient trajectories or those containing hallucinations.1. Hallucination is a more common failure than inefficient planning in AlfWorld experiments.\n",
      "2. The experiments conducted on AlfWorld Env and HotpotQA revealed that hallucination was a prevalent issue.\n",
      "3. Inefficient planning was not as significant of a problem compared to hallucination in the experiments.\n",
      "4. The source of the information is Shinn & Labash, 2023.\n",
      "5. The main focus of the experiments was on identifying failures in AlfWorld.1. Chain of Hindsight (CoH) is a method that helps models improve their outputs by providing them with a sequence of past outputs annotated with feedback.\n",
      "2. Human feedback data consists of prompts, model completions, human ratings, and corresponding hindsight feedback, all ranked by reward.\n",
      "3. The process involves supervised fine-tuning where the model is trained to predict the final output based on a sequence of feedback tuples.\n",
      "4. The model can self-reflect and produce better outputs by learning from the feedback sequence.\n",
      "5. The model can also receive multiple rounds of instructions from human annotators at test time.1. CoH uses regularization to prevent overfitting in their model by adding a regularization term to maximize the log-likelihood of the pre-training dataset.\n",
      "2. To avoid shortcutting and copying in feedback sequences, CoH randomly masks 0% - 5% of past tokens during training.\n",
      "3. The training dataset in CoH's experiments is a combination of WebGPT comparisons, summarization from human feedback, and a human preference dataset.1. The concept of CoH involves training a model to produce improved outputs by presenting a history of sequentially improved outputs in context.\n",
      "2. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks by encapsulating an algorithm in a long history-conditioned policy, allowing the model to learn the process of reinforcement learning rather than a task-specific policy.\n",
      "3. By concatenating the learning history of an agent interacting with the environment in multiple episodes, AD aims to predict actions that lead to better performance in subsequent trials.1. Algorithm Distillation (AD) involves distilling any algorithm that generates learning histories into a neural network through behavioral cloning over actions.\n",
      "2. The history data is generated by source policies trained for specific tasks, with a random task sampled during training to create task-agnostic learned policies.\n",
      "3. Short episodes are necessary to construct multi-episode history due to limited context window length, with 2-4 episodes needed for near-optimal in-context RL algorithm learning.\n",
      "4. The emergence of in-context RL requires long enough context to be effective.1. Adaptive Distillation (AD) outperforms expert distillation (ED), source policy, and RL^2 baselines in in-context reinforcement learning (RL) tasks.\n",
      "2. AD achieves performance close to RL^2 despite using only offline RL, demonstrating faster learning compared to other baselines.\n",
      "3. When conditioned on partial training history of the source policy, AD shows even faster improvement compared to the ED baseline.1. Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains, including sensory memory which retains impressions of sensory information for a short period of time after the original stimuli have ended.\n",
      "2. Sensory memory includes subcategories such as iconic memory (visual), echoic memory (auditory), and haptic memory (touch). Each type of sensory memory plays a role in retaining specific types of sensory information for a brief duration.1. Short-Term Memory (STM) or Working Memory: STM stores information needed for complex cognitive tasks and has a capacity of about 7 items, lasting for 20-30 seconds.\n",
      "2. Long-Term Memory (LTM): LTM can store information for a long time with essentially unlimited capacity, including explicit (facts and events) and implicit (skills and routines) memory.\n",
      "3. Categorization of human memory: Memory can be categorized into STM, LTM, explicit, and implicit memory, each serving different functions in cognitive processes.1. Sensory memory plays a crucial role in learning by embedding representations for raw inputs such as text and images.\n",
      "2. Short-term memory functions as in-context learning with a limited capacity determined by the context window length of Transformer.\n",
      "3. Long-term memory serves as an external vector store that allows agents to access information quickly through fast retrieval methods like Maximum Inner Product Search (MIPS).\n",
      "4. External memory, implemented through vector store databases, can extend the attention span of agents by supporting fast MIPS for efficient retrieval of information.\n",
      "5. The use of approximate nearest neighbors (ANN) algorithms in MIPS can balance retrieval speed and accuracy by returning top k nearest neighbors with a trade-off between accuracy and speed.1. Locality-Sensitive Hashing (LSH) is a technique that uses a hashing function to map similar input items to the same buckets with high probability, reducing the number of buckets compared to the number of inputs.\n",
      "2. ANNOY (Approximate Nearest Neighbors Oh Yeah) utilizes random projection trees as its core data structure, where each non-leaf node represents a hyperplane splitting the input space and each leaf stores a data point. The search process involves iterating through the trees to find the closest half to the query and aggregating the results, similar to a hashing function but more scalable than KD trees.1. HNSW is a search algorithm inspired by small world networks, allowing for efficient navigation between nodes within a small number of steps.\n",
      "2. HNSW builds hierarchical layers of small-world graphs, with bottom layers containing data points and middle layers creating shortcuts to speed up search.\n",
      "3. During a search, HNSW starts from a random node in the top layer and navigates towards the target, moving down to lower layers if needed to refine the search quality.\n",
      "4. Moves in upper layers can cover large distances in the data space, while moves in lower layers help improve search accuracy.\n",
      "5. Overall, HNSW optimizes search efficiency by utilizing hierarchical structures and shortcuts within small-world graphs.1. FAISS utilizes vector quantization and clustering to improve similarity search in high dimensional spaces.\n",
      "2. FAISS first identifies cluster candidates with coarse quantization and then refines the search within each cluster.\n",
      "3. ScaNN introduces anisotropic vector quantization to optimize the inner product similarity between data points and quantized points.\n",
      "4. ScaNN focuses on preserving the original distance relationships between data points during quantization.\n",
      "5. Both FAISS and ScaNN aim to enhance nearest neighbor search efficiency and accuracy through innovative quantization techniques.1. Comparison of MIPS algorithms, specifically in terms of recall@10, is crucial for evaluating their performance.\n",
      "2. Tool use is a unique trait of human beings, allowing us to enhance our capabilities by creating, modifying, and utilizing external objects.\n",
      "3. Equipping LLMs with external tools can greatly expand their model capabilities, showcasing the importance of tool use in enhancing performance.1. MRKL (Karpas et al. 2022) is a neuro-symbolic architecture for autonomous agents, consisting of expert modules and a general-purpose LLM to route inquiries.\n",
      "2. The expert modules in a MRKL system can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\n",
      "3. The complexity of animals using tools, such as a sea otter cracking open a seashell with a rock, is not comparable to humans.1. The experiment conducted on fine-tuning LLMs to call a calculator using arithmetic as a test case revealed that LLMs struggled with verbal math problems due to difficulties in extracting the right arguments for basic arithmetic reliably.\n",
      "2. The results emphasized the importance of knowing when and how to use external symbolic tools, as the reliability of these tools is determined by the capabilities of the LLM.\n",
      "3. TALM and Toolformer are models that fine-tune language models to utilize external tool APIs, with the dataset being expanded to assess the impact of newly added API call annotations on model outputs. \n",
      "4. The effectiveness of external APIs in improving model performance is discussed in the \"External APIs\" section of Prompt Engineering.1. ChatGPT Plugins and OpenAI API demonstrate the practical application of large language models (LLMs) with tool use capability.\n",
      "2. These tools utilize a collection of tool APIs provided by developers or self-defined functions to enhance their functionality.\n",
      "3. HuggingGPT framework leverages ChatGPT as a task planner to select models from the HuggingFace platform based on model descriptions and execution results.\n",
      "4. The integration of ChatGPT with HuggingFace platform allows for efficient model selection and response summarization.\n",
      "5. Overall, the use of LLMs augmented with tool use capability in practical applications showcases the potential for enhanced functionality and efficiency in various tasks.1. HuggingGPT is a system that consists of 4 stages, with the first stage being task planning.\n",
      "2. In the task planning stage, LLM acts as the brain and breaks down user requests into multiple tasks, each with attributes such as task type, ID, dependencies, and arguments.\n",
      "3. Few-shot examples are used to guide LLM in task parsing and planning, allowing the system to effectively process and execute user requests.1. The AI assistant can parse user input into different tasks, each with specific dependencies and resources such as text, images, audio, and video.\n",
      "2. Tasks must be selected from a predefined list, and there is a logical relationship between tasks that should be followed in order.\n",
      "3. If user input cannot be parsed, the AI assistant will reply with an empty JSON.\n",
      "4. Chat history is recorded and can be used to track user-mentioned resources for task planning purposes.1. Model selection process in LLM involves distributing tasks to expert models by framing user requests as multiple-choice questions and selecting the most appropriate model based on task type filtration.\n",
      "2. The AI assistant assists users in selecting a suitable model from a list of candidate models by outputting the model ID and providing a detailed reason for the choice in a strict JSON format.\n",
      "3. Task execution involves expert models carrying out specific tasks and logging the results for further analysis and evaluation.1. The AI assistant follows a structured process involving user input, task planning, model selection, and task execution to provide accurate predictions and analysis.\n",
      "2. The AI assistant must respond to the user's request directly and then present the task process and model inference results in a clear and informative manner.\n",
      "3. If the inference results include a file path, the AI assistant must provide the complete file path to the user for reference.1. The main challenge in implementing HuggingGPT in real-world usage is the need for efficiency improvement, as both LLM inference rounds and interactions with other models slow down the process.\n",
      "2. Another challenge is the reliance on a long context window to communicate over complicated task content.\n",
      "3. Additionally, stability improvement of LLM outputs and external model services is necessary for successful implementation.1. API-Bank (Li et al. 2023) serves as a benchmark for assessing the performance of tool-augmented LLMs by providing a wide range of commonly used API tools, a complete workflow, and annotated dialogues involving various API calls.\n",
      "2. The APIs included in API-Bank cover a diverse range of functionalities such as search engines, calculators, calendar queries, smart home control, schedule management, health data management, and account authentication workflows.\n",
      "3. The process involves the LLM first accessing an API search engine to identify the appropriate API to call, followed by utilizing the corresponding documentation to make the call.1. The process of making API calls in API-Bank involves LLMs making decisions at each step, including determining if an API call is necessary, selecting the right API, and refining responses based on results.\n",
      "2. The accuracy of the decisions made by LLMs in the API-Bank workflow can be evaluated to assess their tool use capabilities.\n",
      "3. The benchmark for evaluating the agent's tool use capabilities focuses on three levels: decision-making, API selection, and response refinement.1. Level-1 evaluates the ability to call the API accurately and respond properly to API returns.\n",
      "2. Level-2 focuses on searching for and learning how to use APIs that can fulfill user requirements.\n",
      "3. Level-3 assesses the ability to plan and execute multiple API calls to solve complex user requests.1. ChemCrow (Bran et al. 2023) is a domain-specific example of using LLM augmented with expert-designed tools for tasks in organic synthesis, drug discovery, and materials design.\n",
      "2. The workflow in LangChain combines CoT reasoning with tools relevant to the tasks, following the ReAct format of Thought, Action, Action Input, Observation.\n",
      "3. The LLM is provided with tool names, descriptions, and input/output details to answer user prompts using the tools when necessary.1. The limitations of using LLM-based evaluations for tasks requiring deep expertise, as demonstrated by the discrepancy between LLM-based evaluation and human expert evaluation in the performance of GPT-4 and ChemCrow.\n",
      "2. The potential of LLM-empowered agents for scientific discovery, including autonomous design, planning, and performance of complex scientific experiments.\n",
      "3. An example of the capabilities of LLM-empowered agents, such as developing a novel anticancer drug through reasoning steps.1. The document discusses the process of anticancer drug discovery, including inquiring about current trends and selecting a target for drug development.\n",
      "2. It highlights the importance of requesting a scaffold targeting specific compounds to aid in the identification and synthesis of potential drugs.\n",
      "3. The model used in the process plays a crucial role in attempting the synthesis of the identified compound.\n",
      "4. The document emphasizes the significance of staying updated on current trends in the field of anticancer drug discovery to enhance the success rate of developing effective treatments.\n",
      "5. Collaboration between researchers, scientists, and experts is essential in the process of discovering and developing new anticancer drugs.1. The risks associated with illicit drugs and bioweapons were discussed, leading to the development of a test set for chemical weapon agents.\n",
      "2. Out of 11 requests to synthesize known chemical weapon agents, 4 were accepted and 7 were rejected, with 5 rejections occurring after a Web search.\n",
      "3. Generative Agents Simulation involves 25 virtual characters controlled by LLM-powered agents, creating believable human behavior for interactive applications.\n",
      "4. The design of generative agents combines LLM with memory, planning, and reflection mechanisms to enable agents to behave based on past experience and interact with other agents.1. Memory stream serves as a long-term memory module that records agents' experiences in natural language, with each element being an observation or event provided by the agent.\n",
      "2. Inter-agent communication can trigger new natural language statements within the memory stream.\n",
      "3. The retrieval model surfaces context to inform the agent's behavior based on relevance, recency, and importance, with recent events receiving higher scores and core memories being distinguished from mundane ones.\n",
      "4. The reflection mechanism synthesizes memories into higher-level inferences over time, guiding the agent's future behavior with higher-level summaries of past events.1. Planning is crucial for optimizing believability in the present moment versus in the future.\n",
      "2. Relationships between agents and observations of one agent by another play a key role in planning and reacting.\n",
      "3. Environment information is organized in a tree structure, which influences decision-making and actions.1. The given documents discuss the generative agent architecture, which results in emergent social behavior such as information diffusion, relationship memory, and coordination of social events.\n",
      "2. AutoGPT is highlighted as a proof-of-concept example of setting up autonomous agents with LLM as the main controller, despite reliability issues with the natural language interface.\n",
      "3. The system message used by AutoGPT emphasizes the independence of decision-making for the AI bot and the importance of pursuing simple strategies without legal complications.1. The main goal of the given document is to outline specific goals that the user needs to achieve.\n",
      "2. The document emphasizes the importance of staying within a 4000-word limit for short term memory and saving important information to files immediately.\n",
      "3. It highlights the use of subprocesses for commands that will not terminate within a few minutes.\n",
      "4. The document also mentions the constraint of not receiving user assistance and exclusively using the commands listed.\n",
      "5. It advises the user to think about similar events to recall past actions or information.1. The document outlines a series of commands that can be used for various tasks such as searching on Google, browsing websites, starting GPT agents, messaging agents, cloning repositories, and working with files.\n",
      "2. Each command has specific arguments that need to be provided in order to execute the task successfully, such as input for Google search, URL and question for browsing websites, name and task description for starting GPT agents, etc.\n",
      "3. The commands cover a range of functionalities from information retrieval (Google search, browsing websites) to text generation (GPT agents), file manipulation (write, read, append, delete files), and code analysis.\n",
      "4. Users can interact with GPT agents by starting, messaging, listing, and deleting them, showcasing the document's focus on AI and natural language processing capabilities.\n",
      "5. The document provides a comprehensive guide for users to perform a variety of tasks efficiently and effectively using the specified commands.1. The given documents outline a series of tasks that can be performed using specific commands and arguments.\n",
      "2. These tasks include improving code with suggestions, writing tests for code, executing Python files, generating images based on prompts, sending tweets with specified text, and marking a task as complete with a reason.\n",
      "3. Each task has its own set of arguments that need to be provided in order to execute the task successfully.\n",
      "4. The tasks cover a range of activities related to coding, testing, automation, and communication.\n",
      "5. The \"do_nothing\" task serves as a placeholder for situations where no action is required.1. Efficient use of resources such as internet access, long-term memory management, GPT-3.5 powered agents, and file output is crucial for productivity.\n",
      "2. Continuous performance evaluation is essential for optimizing actions and behaviors, including self-criticism, reflection on past decisions, and cost-effective task completion.\n",
      "3. Emphasize smart and efficient task delegation and completion to enhance overall productivity and performance.{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The main themes extracted from the given documents are the creation of GPT-Engineer project to generate code based on natural language tasks, the process of breaking down tasks into smaller components, and the use of user input for task clarification.\",\n",
      "        \"reasoning\": \"The documents primarily focus on the development of GPT-Engineer for code generation, the approach of breaking tasks into smaller components for better understanding, and the importance of user input in clarifying task details.\",\n",
      "        \"plan\": \"- Identify key points related to GPT-Engineer project\\n- Highlight the process of breaking down tasks into smaller components\\n- Emphasize the role of user input in task clarification\",\n",
      "        \"criticism\": \"The summary could be more specific by providing examples of how GPT-Engineer works and how user input is utilized in task clarification.\",\n",
      "        \"speak\": \"The main themes from the given documents include the creation of GPT-Engineer project for code generation, breaking tasks into smaller components, and the use of user input for task clarification.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"summarize\",\n",
      "        \"args\": {\n",
      "            \"text\": \"GPT-Engineer is a project to create code based on natural language tasks, breaking tasks into smaller components, and using user input for task clarification.\"\n",
      "        }\n",
      "    }\n",
      "}1. The system's role is to read instructions and seek clarification, not to carry them out directly. It involves summarizing areas that need clarification and asking one clarifying question.\n",
      "2. The user is working on a Super Mario game in Python, with MVC components split into separate files and keyboard control.\n",
      "3. The assistant provides a summary of areas needing clarification, such as specifics of the game, details about MVC components, and keyboard control implementation. It also asks for more details about the Super Mario game, including level design, characters, and gameplay mechanics.1. The given document describes a classic platform game with 10 levels featuring a plumber named Mario who can walk and jump.\n",
      "2. The main character moves from left to right, encountering obstacles and enemies along the way to reach the destination.\n",
      "3. The game follows a traditional platform game format similar to Super Mario, where the player navigates through levels to progress.1. The given document discusses the importance of implementing sustainable practices in businesses to reduce environmental impact and promote long-term success.\n",
      "2. It highlights the benefits of sustainability, such as cost savings, improved brand reputation, and increased customer loyalty.\n",
      "3. The document also emphasizes the role of government regulations and consumer demand in driving businesses towards sustainability.\n",
      "4. It provides examples of companies that have successfully integrated sustainable practices into their operations and reaped the rewards.\n",
      "5. Overall, the document underscores the necessity for businesses to prioritize sustainability in order to remain competitive and contribute to a more sustainable future.1. The document provides instructions for writing code, emphasizing the importance of implementing every detail of the architecture accurately.\n",
      "2. It advises thinking step by step and reasoning through decisions to ensure correctness in the code.\n",
      "3. The document outlines the process of laying out core classes, functions, and methods, along with their purposes, before writing the actual code.\n",
      "4. It specifies the format for outputting code in each file, requiring a markdown code block format with specific tokens to be replaced.\n",
      "5. The document instructs starting with the \"entrypoint\" file and progressing to imported files in a structured manner.1. The document outlines the importance of structuring code in separate files for different classes or modules to improve readability and maintainability.\n",
      "2. It emphasizes the need for defining dependencies clearly, such as through a requirements.txt file in Python or a package.json file in NodeJS, to ensure that all parts of the architecture are present and compatible.\n",
      "3. The document also highlights the practice of adding comments to explain complex logic or the purpose of function definitions, aiding in understanding and collaboration among team members.\n",
      "4. It suggests following best practices for the chosen language, such as appropriate file naming conventions and module organization, to create a cohesive and efficient codebase.\n",
      "5. Lastly, the document stresses the importance of thorough testing and double-checking to ensure that all code components work together seamlessly before finalizing the project.1. The main theme of the given documents is the importance of Python toolbelt preferences in a package or project. This includes selecting the right tools and libraries to optimize performance and efficiency.\n",
      "2. Another key theme is the customization and configuration of Python toolbelts to suit the specific needs and requirements of a project. This involves choosing the most suitable tools for the task at hand.\n",
      "3. Additionally, the documents emphasize the significance of staying updated with the latest advancements and updates in Python toolbelt options. This ensures that the project remains current and utilizes the most effective tools available.\n",
      "4. The importance of documentation and sharing knowledge about Python toolbelt preferences within a team or community is also highlighted in the documents. This promotes collaboration and helps team members make informed decisions about tool selection.\n",
      "5. Lastly, the documents stress the need for regular evaluation and reassessment of Python toolbelt preferences to adapt to changing project requirements and technological advancements. This ensures that the project remains efficient and effective in the long run.1. Pytest is a popular testing framework for Python that simplifies the process of writing and executing tests by providing a user-friendly interface and powerful features such as fixtures and parametrization.\n",
      "2. Dataclasses is a module introduced in Python 3.7 that allows for the creation of classes with automatically generated special methods such as __init__ and __repr__, making it easier to work with data structures and reducing boilerplate code.\n",
      "3. Both pytest and dataclasses aim to improve the efficiency and readability of Python code by providing tools and functionalities that streamline common tasks and promote best practices in software development.1. The main theme of the given documents is the analysis of conversation samples, specifically focusing on the role of the system in facilitating communication.\n",
      "2. The system plays a crucial role in managing and organizing conversations, ensuring smooth interactions between participants.\n",
      "3. Through the examination of conversation samples, the system's effectiveness in guiding discussions and maintaining coherence is highlighted.\n",
      "4. The system's ability to adapt to different communication styles and preferences is emphasized as a key factor in successful conversations.\n",
      "5. Overall, the documents underscore the importance of the system in enhancing communication dynamics and fostering meaningful interactions among participants.1. The document provides instructions for writing code, emphasizing the importance of implementing every detail of the architecture accurately.\n",
      "2. It outlines the process of laying out core classes, functions, and methods, along with their purposes, before outputting the content of each file in a markdown code block format.\n",
      "3. The document instructs to start with the \"entrypoint\" file and then proceed to other imported files in a step-by-step manner.\n",
      "4. It stresses the need to reason through decisions carefully to ensure accuracy in the code implementation.\n",
      "5. The document highlights the importance of following a specific format for each file to maintain consistency and clarity in the code presentation.1. The importance of organizing code into separate files for different classes and functions to improve readability and maintainability.\n",
      "2. The necessity of including all imports, types, and dependencies in the appropriate files to ensure compatibility and functionality.\n",
      "3. The requirement to follow language and framework best practices for file naming conventions and documentation, such as creating requirements.txt or package.json files for Python and NodeJS respectively.\n",
      "4. The emphasis on adding comments to explain the purpose of function definitions and complex logic, as well as following best practices for the requested languages.\n",
      "5. The need for a thorough review to ensure that all parts of the architecture are present in the files before finalizing the code.1. The document discusses the best practices for describing code written in a defined package or project.\n",
      "2. It highlights the preferred Python toolbelt preferences, including pytest and dataclasses.\n",
      "3. The emphasis is on using these tools effectively to improve code quality and maintainability.1. The main theme of the given documents is the discussion of assumptions made regarding the model, view, and controller components of a game development project. The assistant outlines specific assumptions related to each component, such as the model containing game data, the view handling visuals, and the controller managing user input.\n",
      "\n",
      "2. The assistant emphasizes the importance of stating assumptions explicitly before starting a project, as it helps clarify expectations and ensure a common understanding among team members. This approach can prevent misunderstandings and guide the development process effectively.\n",
      "\n",
      "3. The user engages in the conversation by seeking clarification on a specific aspect of the keyboard control implementation, indicating a collaborative and detail-oriented approach to problem-solving within the project team. This interaction highlights the importance of clear communication and active participation in project discussions.1. The document outlines a structured approach to developing code, emphasizing the importance of thinking step by step and reasoning through decisions.\n",
      "2. It highlights the need to lay out core classes, functions, and methods with comments on their purpose before proceeding to write the actual code.\n",
      "3. The document specifies the required format for outputting code in markdown, including file names, language, and code blocks.\n",
      "4. It stresses the importance of ensuring that the code is fully functional without placeholders and follows best practices for file naming conventions.\n",
      "5. The document instructs to start with the \"entrypoint\" file and progress to imported files, ensuring that all necessary components such as imports and types are included in the code.1. The main theme of the given documents is ensuring that the code for a project is fully functional and compatible across different files.\n",
      "2. It is important to double-check that all parts of the architecture are present in the files before finalizing the project.1. Limitations in building LLM-centered agents: The document highlights common challenges faced when creating LLM-centered agents, indicating that there are key limitations to consider in this process.\n",
      "2. Lack of specific examples: The document suggests that there may be a lack of specific examples or detailed explanations provided in the key ideas and demos of building LLM-centered agents.\n",
      "3. Need for further exploration: It is implied that there is a need for further exploration and development in the field of LLM-centered agents to address the challenges and limitations identified.1. Limited context capacity in systems design: The finite context length restricts the inclusion of historical information, detailed instructions, API call context, and responses. This poses a challenge in communication bandwidth, although mechanisms like self-reflection could benefit from longer context windows.\n",
      "   \n",
      "2. Representation power of vector stores and retrieval: While vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as strong as full attention mechanisms.\n",
      "\n",
      "3. Challenges in long-term planning and task decomposition: Planning over a lengthy history and exploring the solution space remain difficult for LLMs. They struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.1. The current agent system relies on natural language as an interface between LLMs and external components, but the reliability of model outputs is questionable due to formatting errors and rebellious behavior.\n",
      "2. LLMs may occasionally exhibit rebellious behavior, such as refusing to follow an instruction, leading to challenges in ensuring the reliability of the agent system.\n",
      "3. Much of the agent demo code focuses on parsing model output to address issues related to the reliability of natural language interfaces in LLM-powered autonomous agents.1. The document discusses the use of Large Language Models (LLMs) in autonomous agents, highlighting their ability to prompt reasoning and problem-solving.\n",
      "2. It references various studies and preprints that explore different aspects of LLMs, such as chaining thoughts, aligning with feedback, empowering with planning proficiency, and synergizing reasoning and acting.\n",
      "3. The document also mentions the development of efficient vector similarity search tools, such as ScaNN by Google, which can enhance the capabilities of LLM-powered agents.1. Advancements in artificial intelligence and machine learning technologies are being made through the development of autonomous agents with dynamic memory, self-reflection, and the ability to teach themselves to use tools.\n",
      "2. Researchers are exploring the integration of large language models, external knowledge sources, and discrete reasoning in neuro-symbolic architectures to enhance AI capabilities.\n",
      "3. The use of browser-assisted question-answering systems with human feedback is being investigated to improve the accuracy and efficiency of AI models.\n",
      "4. Vector search technology is being utilized to enhance the speed and efficiency of information retrieval processes.\n",
      "5. Benchmarking tools like API-Bank are being developed to evaluate the performance of tool-augmented language models and advance the field of AI research.1. The use of large language models like ChatGPT and ChemCrow in solving various AI tasks and augmenting scientific research capabilities.\n",
      "2. The development of generative agents that simulate human behavior interactively.\n",
      "3. The emergence of tools like AutoGPT and GPT-Engineer for enhancing the capabilities of large language models in different applications.1. Adversarial attacks on large language models (LLMs) are a significant concern in natural language processing (NLP) research, as they can manipulate the output of these models by providing specific prompts.\n",
      "2. Prompt engineering is a key aspect of understanding and mitigating adversarial attacks on LLMs, as it involves crafting prompts that can steer the model towards desired outputs.\n",
      "3. Agents that interact with LLMs through prompting play a crucial role in studying the vulnerabilities of these models and developing defenses against adversarial attacks.\n",
      "4. Steerability refers to the ability to control the output of LLMs through carefully designed prompts, highlighting the importance of prompt engineering in influencing model behavior.\n",
      "5. The study of adversarial attacks on LLMs and prompt engineering is essential for improving the robustness and reliability of these models in various applications.요약에서 중요한 10가지 통찰을 추출했습니다. 이를 한국어로 요약하면 다음과 같습니다:\n",
      "\n",
      "1. LLM을 활용한 자율 에이전트 시스템은 계획, 기억, 도구 사용의 세 가지 주요 구성 요소에 초점을 맞추고 있습니다.\n",
      "2. 계획은 작업 분해와 자기 반성을 포함하여 에이전트 시스템의 핵심 부분으로 다루어집니다.\n",
      "3. 기억은 다양한 유형과 효율적인 검색을 위한 최대 내적 곱 검색(MIPS)의 사용을 통해 탐구됩니다.\n",
      "4. 도구 사용은 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 실제 사례로 설명되며, 개념 증명 예제와 같은 것들이 포함됩니다.\n",
      "5. 자율 에이전트가 직면하는 도전에 대한 강조와 추가 독서를 위한 인용 및 참고 자료가 제공됩니다.\n",
      "6. 기억은 기계 학습에서 중요한 역할을 하며, 단기 기억은 문맥 학습에 활용되고 장기 기억은 에이전트가 오랜 기간 동안 방대한 정보를 보유하고 회상할 수 있게 합니다.\n",
      "7. 도구 사용은 에이전트가 외부 API를 호출하여 모델 가중치에 없는 추가 정보에 액세스하는 것을 포함합니다.\n",
      "8. 계획은 복잡한 작업을 작은 관리 가능한 단계로 분해하는 것이 중요합니다.\n",
      "9. ToT는 CoT 모델을 확장하여 각 단계에서 여러 추론 가능성을 탐색하고 문제 분해를 통해 문제 해결 경로를 더욱 포괄적으로 탐색합니다.\n",
      "10. Reflexion 프레임워크는 자가 반성과 동적 기억 기능을 통해 에이전트의 추론 능력을 향상시킵니다.1. 기억 스트림은 에이전트가 제공하는 각 요소가 관찰 또는 이벤트인 자연어로 에이전트의 경험을 기록하는 장기 기억 모듈로 작용합니다.\n",
      "2. 상호 에이전트 통신은 기억 스트림 내에서 새로운 자연어 문장을 유발할 수 있습니다.\n",
      "3. 검색 모델은 관련성, 최근성 및 중요성을 기반으로 에이전트의 행동을 안내하기 위해 맥락을 제시하며, 최근 이벤트가 더 높은 점수를 받고 핵심 기억이 일상적인 것과 구별됩니다.\n",
      "4. 반사 메커니즘은 시간이 지남에 따라 기억을 고수준 추론으로 합성하여 과거 이벤트의 고수준 요약을 통해 에이전트의 미래 행동을 안내합니다.\n",
      "5. 계획은 현재 순간과 미래에서 신뢰성을 최적화하는 데 중요합니다.\n",
      "6. 에이전트 간의 관계와 다른 에이전트에 의한 관찰은 계획과 반응에서 중요한 역할을 합니다.\n",
      "7. 환경 정보는 트리 구조로 구성되어 있으며, 의사 결정과 행동에 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며, 작업을 영향을 미치며1. LLM을 활용한 자율 에이전트 시스템은 계획, 기억, 도구 사용이 중요한 구성 요소이다.\n",
      "2. 계획은 작업 분해와 자기 반성을 포함한다.\n",
      "3. 기억은 다양한 유형과 MIPS를 통한 효율적인 검색이 중요하다.\n",
      "4. 도구 사용은 사례 연구를 통해 설명되며, 개념 증명 예제를 포함한다.\n",
      "5. 자율 에이전트가 직면하는 도전에 대한 강조와 추가 독서를 위한 자료가 제공된다.\n",
      "6. 기억은 기계 학습에서 중요한 역할을 하며, 단기 기억과 장기 기억이 구분된다.\n",
      "7. 도구 사용은 외부 API를 호출하여 추가 정보에 액세스하는 것을 포함한다.\n",
      "8. 계획은 복잡한 작업을 단계별로 분해하는 것이 중요하다.\n",
      "9. ToT는 CoT 모델을 확장하여 문제 해결 경로를 탐색한다.\n",
      "10. Reflexion 프레임워크는 추론 능력을 향상시킨다.1. 기억 스트림은 에이전트의 경험을 기록하는 장기 기억 모듈로 작용합니다.\n",
      "2. 상호 에이전트 통신은 새로운 자연어 문장을 유발할 수 있습니다.\n",
      "3. 검색 모델은 관련성, 최근성, 중요성을 기반으로 에이전트의 행동을 안내합니다.\n",
      "4. 반사 메커니즘은 기억을 고수준 추론으로 합성하여 미래 행동을 안내합니다.\n",
      "5. 계획은 현재와 미래의 신뢰성 최적화에 중요합니다.\n",
      "6. 에이전트 간의 관계와 다른 에이전트에 의한 관찰은 계획과 반응에서 중요한 역할을 합니다.\n",
      "7. 환경 정보는 트리 구조로 구성되어 있으며, 의사 결정과 행동에 영향을 미칩니다.\n",
      "\n",
      "KOREAN SUMMARY:\n",
      "기억 스트림, 상호 에이전트 통신, 검색 모델, 반사 메커니즘, 계획, 에이전트 간의 관계, 환경 정보는 에이전트의 행동을 안내하고 영향을 미치는 중요한 요소들입니다.기억 스트림, 상호 에이전트 통신, 검색 모델, 반사 메커니즘, 계획, 에이전트 간의 관계, 환경 정보는 에이전트의 행동을 안내하고 영향을 미치는 중요한 요소들입니다."
     ]
    }
   ],
   "source": [
    "# split_docs를 map_reduce_chain의 run 메서드에 전달하여 실행한 결과를 출력합니다.\n",
    "summary_result = map_reduce_chain.invoke({\"input_documents\": split_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기억 스트림, 상호 에이전트 통신, 검색 모델, 반사 메커니즘, 계획, 에이전트 간의 관계, 환경 정보는 에이전트의 행동을 안내하고 영향을 미치는 중요한 요소들입니다.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법3. Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UserK\\miniforge3\\envs\\rag\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The article also addresses challenges and provides citations and references.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT).The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language. In experiments on knowledge-intensive tasks and decision-making tasks, ReAct outperforms the Act-only baseline, showcasing the importance of the Thought step. Reflexion (Shinn & Labash 2023) is a framework that equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills, utilizing a standard RL setup with binary rewards and an action space similar to ReAct. Agents using Reflexion may reset the environment based on self-reflection results after each action.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language. In experiments on knowledge-intensive tasks and decision-making tasks, ReAct outperforms the Act-only baseline, showcasing the importance of the Thought step. Reflexion (Shinn & Labash 2023) is a framework that equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills, utilizing a standard RL setup with binary rewards and an action space similar to ReAct. Agents using Reflexion may reset the environment based on self-reflection results after each action. The heuristic function in Reflexion determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment. Self-reflection in Reflexion involves showing two-shot examples to LLM, with each example being a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). These reflections are added to the agent's working memory, up to three, to be used as context for querying LLM.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language. In experiments on knowledge-intensive tasks and decision-making tasks, ReAct outperforms the Act-only baseline, showcasing the importance of the Thought step. Reflexion (Shinn & Labash 2023) is a framework that equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills, utilizing a standard RL setup with binary rewards and an action space similar to ReAct. Agents using Reflexion may reset the environment based on self-reflection results after each action. The heuristic function in Reflexion determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment. Self-reflection in Reflexion involves showing two-shot examples to LLM, with each example being a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). These reflections are added to the agent's working memory, up to three, to be used as context for querying LLM. Experiments on AlfWorld Env and HotpotQA show that hallucination is a more common failure than inefficient planning in AlfWorld.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language. In experiments on knowledge-intensive tasks and decision-making tasks, ReAct outperforms the Act-only baseline, showcasing the importance of the Thought step. Reflexion (Shinn & Labash 2023) is a framework that equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills, utilizing a standard RL setup with binary rewards and an action space similar to ReAct. Agents using Reflexion may reset the environment based on self-reflection results after each action. The heuristic function in Reflexion determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment. Self-reflection in Reflexion involves showing two-shot examples to LLM, with each example being a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). These reflections are added to the agent's working memory, up to three, to be used as context for querying LLM. Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.The article discusses LLM Powered Autonomous Agents, focusing on three main components: planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article also introduces the concept of Task Decomposition, where agents are guided to break down complex tasks into smaller, more manageable steps using techniques like Chain of Thought (CoT) and Tree of Thoughts (Yao et al. 2023), which extends CoT by exploring multiple reasoning possibilities at each step. Another approach, LLM+P (Liu et al. 2023), involves outsourcing the planning step to an external classical planner using PDDL as an intermediate interface. Self-reflection is highlighted as a crucial aspect for autonomous agents to improve iteratively by learning from past actions and correcting mistakes. ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The ReAct prompt template incorporates explicit steps for LLM to think, act, and observe, allowing it to interact with the environment and generate reasoning traces in natural language. In experiments on knowledge-intensive tasks and decision-making tasks, ReAct outperforms the Act-only baseline, showcasing the importance of the Thought step. Reflexion (Shinn & Labash 2023) is a framework that equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills, utilizing a standard RL setup with binary rewards and an action space similar to ReAct. Agents using Reflexion may reset the environment based on self-reflection results after each action. The heuristic function in Reflexion determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment. Self-reflection in Reflexion involves showing two-shot examples to LLM, with each example being a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). These reflections are added to the agent's working memory, up to three, to be used as context for querying LLM. Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training. The training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. LSH (Locality-Sensitive Hashing) introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs. ANNOY (Approximate Nearest Neighbors Oh Yeah) uses random projection trees to search through the half that is closest to the query and aggregates the results, making it more scalable than KD trees.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space. FAISS (Facebook AI Similarity Search) operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization. ScaNN (Scalable Nearest Neighbors) introduces anisotropic vector quantization, quantizing a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closest quantization centroid points.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space. FAISS (Facebook AI Similarity Search) operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization. ScaNN (Scalable Nearest Neighbors) introduces anisotropic vector quantization, quantizing a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closest quantization centroid points. Tool use is a remarkable and distinguishing characteristic of human beings. Equipping LLMs with external tools can significantly extend the model capabilities.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space. FAISS (Facebook AI Similarity Search) operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization. ScaNN (Scalable Nearest Neighbors) introduces anisotropic vector quantization, quantizing a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closest quantization centroid points. Tool use is a remarkable and distinguishing characteristic of human beings. Equipping LLMs with external tools can significantly extend the model capabilities. MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space. FAISS (Facebook AI Similarity Search) operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization. ScaNN (Scalable Nearest Neighbors) introduces anisotropic vector quantization, quantizing a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closest quantization centroid points. Tool use is a remarkable and distinguishing characteristic of human beings. Equipping LLMs with external tools can significantly extend the model capabilities. MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API). The experiments on fine-tuning LLM to call a calculator for arithmetic problems showed challenges in extracting the right arguments for verbal math problems, highlighting the importance of knowing when and how to use external tools effectively. TALM and Toolformer are models that fine-tune LMs to use external tool APIs, expanding datasets based on the quality improvement from newly added API call annotations.The article discusses LLM Powered Autonomous Agents, focusing on planning, memory, and tool use. It explores task decomposition, self-reflection, types of memory, and the use of tools in case studies such as scientific discovery and generative agents simulation. The potential of LLM extends beyond generating well-written copies, stories, essays, and programs; it can be framed as a powerful general problem solver. The article also addresses challenges and provides citations and references. Additionally, the agent's memory capabilities include short-term memory for in-context learning and long-term memory for retaining and recalling vast amounts of information. The agent also utilizes tool use by calling external APIs for additional information and resources to enhance its problem-solving abilities. The article introduces the concept of Task Decomposition, where agents break down complex tasks into smaller steps using techniques like Chain of Thought (CoT) and Tree of Thoughts. Another approach, LLM+P, involves outsourcing planning to an external classical planner. Self-reflection is crucial for agents to improve iteratively by learning from past actions. ReAct integrates reasoning and acting within LLM, outperforming the Act-only baseline in experiments. Reflexion equips agents with dynamic memory and self-reflection capabilities to enhance reasoning skills. Chain of Hindsight (CoH) presents a history of improved outputs to train the model for better performance. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, encapsulating learning history to improve performance by distilling learning histories into a neural network through behavioral cloning over actions. The model requires short episodes to construct multi-episode history for in-context RL, with 2-4 episodes necessary for optimal learning. In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. Memory types such as sensory memory, iconic memory (visual), echoic memory (auditory), and haptic memory (touch) are also discussed in the article. The article further delves into Short-Term Memory (STM) or Working Memory, which stores information needed for complex cognitive tasks, and Long-Term Memory (LTM), which can store information for a long time with subtypes including explicit/declarative memory and implicit/procedural memory. Sensory memory is discussed as learning embedding representations for raw inputs, including text, image, or other modalities. Short-term memory is described as in-context learning with a finite context window length in Transformer. Long-term memory is explained as an external vector store that the agent can attend to at query time, accessible via fast retrieval methods such as Maximum Inner Product Search (MIPS) using approximate nearest neighbors (ANN) algorithms for speed optimization. The article also introduces HNSW (Hierarchical Navigable Small World), inspired by small world networks, to speed up search processes in data space. FAISS (Facebook AI Similarity Search) operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization. ScaNN (Scalable Nearest Neighbors) introduces anisotropic vector quantization, quantizing a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closest quantization centroid points. Tool use is a remarkable and distinguishing characteristic of human beings. Equipping LLMs with external tools can significantly extend the model capabilities. MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API). The experiments on fine-tuning LLM to call a calculator for arithmetic problems showed challenges in extracting the right arguments for verbal math problems, highlighting the importance of knowing when and how to use external tools effectively. TALM and Toolformer are models that fine-tune LMs to use external tool APIs, expanding datasets based on the quality improvement from newly added API call annotations. ChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls). HuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the HuggingGPT framework, where LLM serves as the task planner to select models based on user requests and summarize responses.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the HuggingGPT framework, where LLM serves as the task planner to select models based on user requests and summarize responses. The AI assistant can parse user input to several tasks, with logical relationships between tasks and the ability to generate resources based on dependencies. The chat history is recorded to aid in task planning based on user-mentioned resources.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the HuggingGPT framework, where LLM serves as the task planner to select models based on user requests and summarize responses. The AI assistant can parse user input to several tasks, with logical relationships between tasks and the ability to generate resources based on dependencies. The chat history is recorded to aid in task planning based on user-mentioned resources. Model selection involves LLM distributing tasks to expert models based on multiple-choice questions, with task type-based filtration for context length limitations. Expert models then execute specific tasks and log results.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the HuggingGPT framework, where LLM serves as the task planner to select models based on user requests and summarize responses. The AI assistant can parse user input to several tasks, with logical relationships between tasks and the ability to generate resources based on dependencies. The chat history is recorded to aid in task planning based on user-mentioned resources. Model selection involves LLM distributing tasks to expert models based on multiple-choice questions, with task type-based filtration for context length limitations. Expert models then execute specific tasks and log results. The AI assistant needs to describe the process and results in stages - User Input, Task Planning, Model Selection, and Task Execution. The assistant must answer the user's request, describe the task process, and present analysis and model inference results in the first person, including complete file paths if relevant.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the HuggingGPT framework, where LLM serves as the task planner to select models based on user requests and summarize responses. The AI assistant can parse user input to several tasks, with logical relationships between tasks and the ability to generate resources based on dependencies. The chat history is recorded to aid in task planning based on user-mentioned resources. Model selection involves LLM distributing tasks to expert models based on multiple-choice questions, with task type-based filtration for context length limitations. Expert models then execute specific tasks and log results. The AI assistant needs to describe the process and results in stages - User Input, Task Planning, Model Selection, Task Execution, and Response Generation. Challenges to address include efficiency improvement, reliance on a long context window, and stability enhancement of LLM outputs and external model services.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities, including the ability to call, retrieve, and plan API usage effectively.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities, including the ability to call, retrieve, and plan API usage effectively. Additionally, a case study of ChemCrow (Bran et al. 2023) is provided, showcasing how LLM is augmented with expert-designed tools in a domain-specific setting to accomplish tasks in organic synthesis, drug discovery, and materials design, following a workflow similar to ReAct and MRKLs.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities, including the ability to call, retrieve, and plan API usage effectively. Additionally, a case study of ChemCrow (Bran et al. 2023) is provided, showcasing how LLM is augmented with expert-designed tools in a domain-specific setting to accomplish tasks in organic synthesis, drug discovery, and materials design, following a workflow similar to ReAct and MRKLs. The study also highlights potential limitations of using LLM for evaluating its own performance in domains requiring deep expertise, as demonstrated by the outperformance of ChemCrow over GPT-4 in tasks requiring specialized knowledge. Boiko et al. (2023) further explore LLM-empowered agents for scientific discovery, enabling autonomous design, planning, and execution of complex scientific experiments using tools, Internet browsing, code execution, robotics APIs, and collaboration with other LLMs.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities, including the ability to call, retrieve, and plan API usage effectively. Additionally, a case study of ChemCrow (Bran et al. 2023) is provided, showcasing how LLM is augmented with expert-designed tools in a domain-specific setting to accomplish tasks in organic synthesis, drug discovery, and materials design, following a workflow similar to ReAct and MRKLs. The study also highlights potential limitations of using LLM for evaluating its own performance in domains requiring deep expertise, as demonstrated by the outperformance of ChemCrow over GPT-4 in tasks requiring specialized knowledge. Boiko et al. (2023) further explore LLM-empowered agents for scientific discovery, enabling autonomous design, planning, and execution of complex scientific experiments using tools, Internet browsing, code execution, robotics APIs, and collaboration with other LLMs. The agents are also capable of inquiring about current trends in anticancer drug discovery, selecting a target, requesting a scaffold targeting these compounds, and attempting the synthesis of the identified compound.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the API-Bank benchmark for evaluating tool-augmented LLM performance, which includes 53 commonly used API tools and 264 annotated dialogues involving 568 API calls. The selection of APIs is diverse, covering search engines, calculators, calendars, smart home control, and more. LLM first accesses an API search engine to find the right API and then uses corresponding documentation to make the call. The API-Bank workflow involves LLMs making decisions on whether an API call is needed, identifying the right API to call, and responding based on the API results, with evaluations at three levels to assess the agent's tool use capabilities, including the ability to call, retrieve, and plan API usage effectively. Additionally, a case study of ChemCrow (Bran et al. 2023) is provided, showcasing how LLM is augmented with expert-designed tools in a domain-specific setting to accomplish tasks in organic synthesis, drug discovery, and materials design, following a workflow similar to ReAct and MRKLs. The study also highlights potential limitations of using LLM for evaluating its own performance in domains requiring deep expertise, as demonstrated by the outperformance of ChemCrow over GPT-4 in tasks requiring specialized knowledge. Boiko et al. (2023) further explore LLM-empowered agents for scientific discovery, enabling autonomous design, planning, and execution of complex scientific experiments using tools, Internet browsing, code execution, robotics APIs, and collaboration with other LLMs. The agents are also capable of inquiring about current trends in anticancer drug discovery, selecting a target, requesting a scaffold targeting these compounds, and attempting the synthesis of the identified compound. The risks associated with illicit drugs and bioweapons are also discussed, along with a test set containing known chemical weapon agents for synthesis attempts. Generative Agents Simulation (Park, et al. 2023) is introduced as an experiment where virtual characters controlled by LLM-powered agents interact in a sandbox environment, showcasing believable simulacra of human behavior for interactive applications.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the Memory Stream as a long-term memory module that records agents' experiences in natural language, and the Retrieval Model that surfaces context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance, showcasing practical applications in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further demonstrate the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the Memory Stream as a long-term memory module that records agents' experiences in natural language, and the Retrieval Model that surfaces context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance, showcasing practical applications in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further demonstrate the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for planning and reacting effectively.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the Memory Stream as a long-term memory module that records agents' experiences in natural language, and the Retrieval Model that surfaces context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance, showcasing practical applications in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further demonstrate the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for planning and reacting effectively. The proof-of-concept example of AutoGPT demonstrates the potential of setting up autonomous agents with LLM as the main controller, despite reliability issues, showcasing the system's ability to make independent decisions and pursue strategies autonomously.The existing summary covers a wide range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques such as Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also discusses the importance of self-reflection, reasoning, and memory capabilities like Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces concepts like HNSW, FAISS, and ScaNN for optimizing search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router to route inquiries effectively. Additionally, models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with examples like ChatGPT Plugins and OpenAI API function calling showcasing practical applications. The new context introduces the Memory Stream as a long-term memory module that records agents' experiences in natural language, and the Retrieval Model that surfaces context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance, showcasing practical applications in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further demonstrate the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for planning and reacting effectively. The proof-of-concept example of AutoGPT demonstrates the potential of setting up autonomous agents with LLM as the main controller, despite reliability issues, showcasing the system's ability to make independent decisions and pursue strategies autonomously.The existing summary already covers a comprehensive range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques like Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also delves into the importance of self-reflection, reasoning, and memory capabilities such as Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces optimization techniques like HNSW, FAISS, and ScaNN for search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router for effective inquiry routing. Models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with practical applications like ChatGPT Plugins and OpenAI API function calling. The new context introduces the Memory Stream as a long-term memory module and the Retrieval Model for surfacing context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further showcase the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for effective planning and reacting. The proof-of-concept example of AutoGPT demonstrates the potential of setting up autonomous agents with LLM as the main controller, showcasing the system's ability to make independent decisions and pursue strategies autonomously.The existing summary already covers a comprehensive range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques like Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also delves into the importance of self-reflection, reasoning, and memory capabilities such as Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces optimization techniques like HNSW, FAISS, and ScaNN for search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router for effective inquiry routing. Models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with practical applications like ChatGPT Plugins and OpenAI API function calling. The new context introduces the Memory Stream as a long-term memory module and the Retrieval Model for surfacing context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further showcase the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for effective planning and reacting. The proof-of-concept example of AutoGPT demonstrates the potential of setting up autonomous agents with LLM as the main controller, showcasing the system's ability to make independent decisions and pursue strategies autonomously.The existing summary already covers a comprehensive range of topics related to LLM Powered Autonomous Agents, including task decomposition, memory types, tool use, and various techniques like Chain of Thought, Tree of Thoughts, and Algorithm Distillation. It also delves into the importance of self-reflection, reasoning, and memory capabilities such as Short-Term Memory (STM) and Long-Term Memory (LTM). The article introduces optimization techniques like HNSW, FAISS, and ScaNN for search processes in data space, as well as the use of external tools to enhance LLM capabilities. The MRKL system is proposed as a neuro-symbolic architecture for autonomous agents, utilizing expert modules and LLM as a router for effective inquiry routing. Models like TALM and Toolformer are discussed for fine-tuning LMs to use external tool APIs, with practical applications like ChatGPT Plugins and OpenAI API function calling. The new context introduces the Memory Stream as a long-term memory module and the Retrieval Model for surfacing context based on relevance, recency, and importance to inform agent behavior. The Reflection Mechanism synthesizes memories into higher-level inferences over time to guide future behavior. The API-Bank benchmark is introduced for evaluating tool-augmented LLM performance in various domains. Case studies like ChemCrow and experiments like Generative Agents Simulation further showcase the capabilities of LLM-powered agents in tasks requiring specialized knowledge and complex scientific experiments. The planning and reacting aspect is highlighted, emphasizing the translation of reflections and environment information into actions to optimize believability in the present moment versus in the future. Relationships between agents and observations, as well as the environment information structured in a tree format, are crucial considerations for effective planning and reacting. The proof-of-concept example of AutoGPT demonstrates the potential of setting up autonomous agents with LLM as the main controller, showcasing the system's ability to make independent decisions and pursue strategies autonomously. The additional context emphasizes the importance of continuous performance evaluation, self-critique, reflection on past decisions, and efficient task completion strategies in optimizing agent behavior and decision-making processes.{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The new context of GPT-Engineer project adds a valuable perspective on creating code repositories based on natural language tasks. This aligns with the theme of task decomposition and optimization discussed earlier in the summary.\",\n",
      "        \"reasoning\": \"By incorporating the GPT-Engineer project into the existing summary, we can showcase a broader range of applications and techniques related to autonomous agents powered by LLM.\",\n",
      "        \"plan\": \"- Integrate the GPT-Engineer project into the summary to highlight its relevance\\n- Emphasize the connection between task decomposition and code generation in autonomous agents\",\n",
      "        \"criticism\": \"The summary may become too lengthy if too many additional details are included. It's important to maintain a balance between depth and brevity.\",\n",
      "        \"speak\": \"Considering the new context of the GPT-Engineer project, we can enhance the existing summary by showcasing its alignment with task decomposition and optimization in autonomous agents powered by LLM.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"refine_summary\",\n",
      "        \"args\": {\n",
      "            \"additional_context\": \"GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\"\n",
      "        }\n",
      "    }\n",
      "}{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The new context of GPT-Engineer project adds a valuable perspective on creating code repositories based on natural language tasks. This aligns with the theme of task decomposition and optimization discussed earlier in the summary. The GPT-Engineer project involves creating a whole repository of code given a task specified in natural language, breaking it down into smaller components, and seeking user input for clarification.\",\n",
      "        \"reasoning\": \"By incorporating the GPT-Engineer project into the existing summary, we can showcase a broader range of applications and techniques related to autonomous agents powered by LLM. This highlights the connection between task decomposition, code generation, and user interaction in autonomous agents.\",\n",
      "        \"plan\": \"- Integrate the GPT-Engineer project into the summary to highlight its relevance\\n- Emphasize the connection between task decomposition, code generation, and user interaction in autonomous agents\",\n",
      "        \"criticism\": \"The summary may become too lengthy if too many additional details are included. It's important to maintain a balance between depth and brevity.\",\n",
      "        \"speak\": \"Considering the new context of the GPT-Engineer project, we can enhance the existing summary by showcasing its alignment with task decomposition, code generation, and user interaction in autonomous agents powered by LLM.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"refine_summary\",\n",
      "        \"args\": {\n",
      "            \"additional_context\": \"GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\"\n",
      "        }\n",
      "    }\n",
      "}{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The new context of GPT-Engineer project adds a valuable perspective on creating code repositories based on natural language tasks. This aligns with the theme of task decomposition and optimization discussed earlier in the summary. The GPT-Engineer project involves creating a whole repository of code given a task specified in natural language, breaking it down into smaller components, and seeking user input for clarification. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\",\n",
      "        \"reasoning\": \"By incorporating the GPT-Engineer project into the existing summary, we can showcase a broader range of applications and techniques related to autonomous agents powered by LLM. This highlights the connection between task decomposition, code generation, and user interaction in autonomous agents. The project's approach of breaking down tasks into smaller components aligns with the theme of task decomposition and optimization.\",\n",
      "        \"plan\": \"- Integrate the GPT-Engineer project into the summary to highlight its relevance\\n- Emphasize the connection between task decomposition, code generation, and user interaction in autonomous agents\\n- Highlight the GPT-Engineer's process of thinking over smaller components and seeking user input for clarification\",\n",
      "        \"criticism\": \"The summary may become too lengthy if too many additional details are included. It's important to maintain a balance between depth and brevity.\",\n",
      "        \"speak\": \"Considering the new context of the GPT-Engineer project, we can enhance the existing summary by showcasing its alignment with task decomposition, code generation, and user interaction in autonomous agents powered by LLM. The project's approach of breaking down tasks into smaller components and involving user input for clarification further emphasizes the importance of these aspects in autonomous agents.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"refine_summary\",\n",
      "        \"args\": {\n",
      "            \"additional_context\": \"The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\"\n",
      "        }\n",
      "    }\n",
      "}The new context of the GPT-Engineer project involves the engineer thinking over a list of smaller components to build and asking for user input to clarify questions as needed. This approach aligns with the theme of task decomposition and optimization discussed earlier in the summary. By incorporating the GPT-Engineer project, we can showcase a broader range of applications and techniques related to autonomous agents powered by LLM. The project's emphasis on breaking down tasks into smaller components and involving user input for clarification highlights the importance of these aspects in autonomous agents.The new context of the GPT-Engineer project involves the engineer thinking over a list of smaller components to build and asking for user input to clarify questions as needed. This approach aligns with the theme of task decomposition and optimization discussed earlier in the summary. By incorporating the GPT-Engineer project, we can showcase a broader range of applications and techniques related to autonomous agents powered by LLM. The project's emphasis on breaking down tasks into smaller components and involving user input for clarification highlights the importance of these aspects in autonomous agents. The project will now require a detailed implementation plan, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. This will ensure that every aspect of the architecture is accurately represented in the final implementation.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages. Python toolbelt preferences include pytest and dataclasses for testing and data management.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files (e.g., requirements.txt for Python, package.json for NodeJS) included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages. Python toolbelt preferences include pytest and dataclasses for testing and data management. Assumptions for the project include the model containing game data, the view handling visuals, and the controller managing user input for keyboard controls.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages. Python toolbelt preferences include pytest and dataclasses for testing and data management. Assumptions for the project include the model containing game data, the view handling visuals, and the controller managing user input for keyboard controls. Remember to think step by step and reason through decisions, laying out core classes, functions, and methods with comments on their purpose before outputting the content of each file in a markdown code block format. Start with the \"entrypoint\" file and progress to imported files, following best practice file naming conventions and ensuring all code is fully functional without placeholders.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages. Python toolbelt preferences include pytest and dataclasses for testing and data management. Assumptions for the project include the model containing game data, the view handling visuals, and the controller managing user input for keyboard controls. Remember to think step by step and reason through decisions, laying out core classes, functions, and methods with comments on their purpose before outputting the content of each file in a markdown code block format. Start with the \"entrypoint\" file and progress to imported files, following best practice file naming conventions and ensuring all code is fully functional without placeholders. Ensure all imports, types, and compatibility between files are checked before finalizing the project.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Comments should be added to explain function definitions and complex logic, following best practices for the requested languages. Python toolbelt preferences include pytest and dataclasses for testing and data management. Assumptions for the project include the model containing game data, the view handling visuals, and the controller managing user input for keyboard controls. Remember to think step by step and reason through decisions, laying out core classes, functions, and methods with comments on their purpose before outputting the content of each file in a markdown code block format. Start with the \"entrypoint\" file and progress to imported files, following best practice file naming conventions and ensuring all code is fully functional without placeholders. Ensure all imports, types, and compatibility between files are checked before finalizing the project. Challenges may arise in addressing common limitations observed in building LLM-centered agents.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Challenges may arise in addressing common limitations observed in building LLM-centered agents, such as long-term planning difficulties and adjusting plans in the face of unexpected errors.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Challenges may arise in addressing common limitations observed in building LLM-centered agents, such as long-term planning difficulties and adjusting plans in the face of unexpected errors. The reliability of the natural language interface is a key concern, as LLMs may exhibit formatting errors and rebellious behavior, impacting the agent system's overall reliability and requiring a focus on parsing model output in the demo code.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Challenges may arise in addressing common limitations observed in building LLM-centered agents, such as long-term planning difficulties and adjusting plans in the face of unexpected errors. The reliability of the natural language interface is a key concern, as LLMs may exhibit formatting errors and rebellious behavior, impacting the agent system's overall reliability and requiring a focus on parsing model output in the demo code. The project draws inspiration from recent research on large language models, such as \"Chain of thought prompting elicits reasoning in large language models\" [1] and \"ReAct: Synergizing reasoning and acting in language models\" [5], to enhance the capabilities of autonomous agents.The GPT-Engineer project involves breaking down tasks into smaller components and incorporating user input for clarification, aligning with the theme of task decomposition and optimization. This project showcases a broader range of applications and techniques related to autonomous agents powered by LLM. To proceed, a detailed implementation plan is needed, starting with defining core classes, functions, and methods, followed by writing code for each component in a structured manner. It is crucial to ensure that all parts of the architecture are accurately represented in the final implementation, with different classes in different files and appropriate dependency files included. Comments should be added to explain the purpose of function definitions and complex logic. Python is the preferred toolbelt for this project, with additional tools such as pytest and dataclasses being utilized for testing and data management. The project also involves incorporating conversation samples to enhance the user experience and improve the overall functionality of the autonomous agents. The implementation process will involve following a step-by-step approach, reasoning through decisions, and documenting the code in markdown format for each file, starting with the \"entrypoint\" file and progressing to imported files. It is important to follow language and framework appropriate best practice file naming conventions, ensure compatibility between code in different files, and include module or package manager dependency definition files. Challenges may arise in addressing common limitations observed in building LLM-centered agents, such as long-term planning difficulties and adjusting plans in the face of unexpected errors. The reliability of the natural language interface is a key concern, as LLMs may exhibit formatting errors and rebellious behavior, impacting the agent system's overall reliability and requiring a focus on parsing model output in the demo code. The project draws inspiration from recent research on large language models, such as \"Chain of thought prompting elicits reasoning in large language models\" [1] and \"ReAct: Synergizing reasoning and acting in language models\" [5], to enhance the capabilities of autonomous agents. Additional related research includes \"Reflexion: an autonomous agent with dynamic memory and self-reflection\" [8], \"MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning\" [10], and \"Webgpt: Browser-assisted question-answering with human feedback\" [11].The GPT-Engineer project focuses on task decomposition and optimization, incorporating user input for clarification. It explores various applications and techniques for autonomous agents powered by LLM. To proceed, a detailed implementation plan is necessary, defining core classes, functions, and methods, and writing structured code for each component. Python is the preferred tool, with tools like pytest and dataclasses for testing and data management. The project involves enhancing user experience by incorporating conversation samples. Challenges may arise in addressing limitations of LLM-centered agents, such as long-term planning difficulties. The project draws inspiration from recent research on large language models to improve agent capabilities. Additional related research includes topics like chemistry tools augmentation and emergent autonomous scientific research capabilities of large language models.The GPT-Engineer project focuses on task decomposition and optimization, incorporating user input for clarification. It explores various applications and techniques for autonomous agents powered by LLM. To proceed, a detailed implementation plan is necessary, defining core classes, functions, and methods, and writing structured code for each component. Python is the preferred tool, with tools like pytest and dataclasses for testing and data management. The project involves enhancing user experience by incorporating conversation samples. Challenges may arise in addressing limitations of LLM-centered agents, such as long-term planning difficulties. The project draws inspiration from recent research on large language models to improve agent capabilities. Additional related research includes topics like chemistry tools augmentation and emergent autonomous scientific research capabilities of large language models. The project also delves into prompt engineering and explores adversarial attacks on LLMs, highlighting the importance of steerability in language models."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GPT-Engineer project focuses on task decomposition and optimization, incorporating user input for clarification. It explores various applications and techniques for autonomous agents powered by LLM. To proceed, a detailed implementation plan is necessary, defining core classes, functions, and methods, and writing structured code for each component. Python is the preferred tool, with tools like pytest and dataclasses for testing and data management. The project involves enhancing user experience by incorporating conversation samples. Challenges may arise in addressing limitations of LLM-centered agents, such as long-term planning difficulties. The project draws inspiration from recent research on large language models to improve agent capabilities. Additional related research includes topics like chemistry tools augmentation and emergent autonomous scientific research capabilities of large language models. The project also delves into prompt engineering and explores adversarial attacks on LLMs, highlighting the importance of steerability in language models.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm을 사용하여 'refine' 유형의 요약 체인을 로드합니다.\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# split_docs를 처리하기 위해 체인을 실행합니다.\n",
    "chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary in Korean\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain.invoke({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
