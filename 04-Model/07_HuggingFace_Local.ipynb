{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 정보로드를 위한 라이브러리\n",
    "# 설치: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH04-Models\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH04-Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ./cache/ 경로에 다운로드 받도록 설정\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./cache/\"\n",
    "os.environ[\"HF_HOME\"] = \"./cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/43.6 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 710.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (0.24.0)\n",
      "Collecting numpy<2.0,>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/9.3 MB 11.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/9.3 MB 14.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.3 MB 17.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.5/9.3 MB 20.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.8/9.3 MB 21.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.3 MB 23.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.3 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 27.1 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.4/287.4 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.2/2.2 MB 46.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, numpy, tokenizers, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed numpy-1.26.4 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\UserK\\miniforge3\\envs\\rag\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\UserK\\miniforge3\\envs\\rag\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached h5py-3.11.0-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.0-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp310-cp310-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\userk\\miniforge3\\envs\\rag\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.0-cp310-cp310-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp310-cp310-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/385.0 MB 38.0 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 3.1/385.0 MB 39.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 6.2/385.0 MB 49.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 9.6/385.0 MB 55.9 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 12.4/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 12.7/385.0 MB 50.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 12.9/385.0 MB 43.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 13.3/385.0 MB 36.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 15.1/385.0 MB 34.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 18.4/385.0 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 21.5/385.0 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 24.7/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 27.8/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 31.4/385.0 MB 73.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 32.2/385.0 MB 54.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 32.7/385.0 MB 46.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 34.4/385.0 MB 43.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 37.0/385.0 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 40.2/385.0 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 43.1/385.0 MB 59.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 46.3/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 49.6/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 53.2/385.0 MB 73.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 56.1/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 59.0/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 62.0/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 65.1/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 68.2/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 71.2/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 74.7/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 77.9/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 81.2/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 84.2/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 87.7/385.0 MB 73.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 89.2/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 89.3/385.0 MB 54.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 89.3/385.0 MB 43.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 89.4/385.0 MB 34.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 89.7/385.0 MB 29.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 91.5/385.0 MB 28.4 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 94.6/385.0 MB 28.5 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 97.7/385.0 MB 27.3 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 100.6/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 103.8/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 105.9/385.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 108.7/385.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 111.5/385.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 114.6/385.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 117.9/385.0 MB 59.8 MB/s eta 0:00:05\n",
      "   ------------ -------------------------- 121.0/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------------ -------------------------- 124.3/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------ -------------------------- 127.3/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 130.5/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 131.8/385.0 MB 54.4 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 133.9/385.0 MB 50.4 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 136.2/385.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 139.1/385.0 MB 50.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 142.4/385.0 MB 59.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 145.1/385.0 MB 65.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 147.8/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 151.1/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 151.2/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 151.3/385.0 MB 43.7 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 151.4/385.0 MB 38.6 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 151.6/385.0 MB 31.2 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 152.0/385.0 MB 27.3 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 154.5/385.0 MB 26.2 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 157.2/385.0 MB 26.2 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 160.1/385.0 MB 26.2 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 162.8/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 165.8/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 169.1/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 171.6/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 174.6/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 176.8/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 179.8/385.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 182.7/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 185.6/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 188.7/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 191.9/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 195.2/385.0 MB 73.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 198.3/385.0 MB 72.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 200.7/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 203.6/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 203.8/385.0 MB 50.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 204.1/385.0 MB 38.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 205.9/385.0 MB 36.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 208.5/385.0 MB 36.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 211.4/385.0 MB 36.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 213.9/385.0 MB 38.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 217.0/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 219.9/385.0 MB 59.8 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.1/385.0 MB 54.7 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 225.3/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 228.5/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 231.7/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 234.7/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 236.8/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 237.7/385.0 MB 50.1 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 238.4/385.0 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 239.2/385.0 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 239.9/385.0 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 242.5/385.0 MB 34.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 245.4/385.0 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 248.2/385.0 MB 38.6 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 251.0/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 253.8/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 256.8/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 259.8/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 262.9/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 266.2/385.0 MB 73.1 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 268.8/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 272.1/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 275.0/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 278.1/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 281.0/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 284.2/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 287.3/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 290.0/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 293.0/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 295.7/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 298.7/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 301.4/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 304.0/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 305.3/385.0 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 305.4/385.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 305.5/385.0 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 305.8/385.0 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 306.7/385.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 309.6/385.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 312.3/385.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 315.2/385.0 MB 28.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 318.4/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 321.3/385.0 MB 65.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 324.2/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 327.3/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 329.6/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 332.8/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 335.7/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 338.2/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 341.3/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 344.3/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 347.3/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 350.6/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 353.6/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 356.8/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 360.1/385.0 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 363.4/385.0 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 366.3/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 368.3/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.7/385.0 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 372.0/385.0 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.9/385.0 MB 50.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.7/385.0 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.4/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 16.0 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.11.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 36.2 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.4.0-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 74.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 67.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 58.4 MB/s eta 0:00:00\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp310-cp310-win_amd64.whl (267 kB)\n",
      "   ---------------------------------------- 0.0/267.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 267.2/267.2 kB ? eta 0:00:00\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, h5py, google-pasta, gast, astunparse, absl-py, werkzeug, markdown-it-py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 rich-13.7.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 werkzeug-3.0.3 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForCausalLM\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, pipeline\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Hugging Face pipeline을 초기화합니다.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\UserK\\miniforge3\\envs\\rag\\lib\\site-packages\\transformers\\utils\\import_utils.py:1507\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1507\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\UserK\\miniforge3\\envs\\rag\\lib\\site-packages\\transformers\\utils\\import_utils.py:1486\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForCausalLM\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_auth_token=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_auth_token=True)\n",
    "# Hugging Face pipeline을 초기화합니다.\n",
    "generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model= model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    top_k=50,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# LangChain HuggingFacePipeline을 초기화합니다.\n",
    "llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "# 텍스트 생성을 수행합니다.\n",
    "response = llm.invoke(\"Hugging Face is\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
