{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Retrieval GroundCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LANGGRAPH\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LANGGRAPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_upstage\n",
      "  Downloading langchain_upstage-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain_upstage) (0.2.28)\n",
      "Requirement already satisfied: langchain-openai<0.2.0,>=0.1.3 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain_upstage) (0.1.20)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.2.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain_upstage) (4.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain_upstage) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (4.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.37.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2024.7.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_upstage) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_upstage) (3.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_upstage) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_upstage) (2.20.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (2024.5.15)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anhye\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.4.6)\n",
      "Downloading langchain_upstage-0.1.7-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: langchain_upstage\n",
      "Successfully installed langchain_upstage-0.1.7\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_upstage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "pdf = PDFRetrievalChain([\"../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 (미리내공방) .pdf\"]).create_chain()\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# GraphState 상태를 저장하는 용도로 사용합니다.\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # 질문\n",
    "    context: str  # 문서의 검색 결과\n",
    "    answer: str  # 답변\n",
    "    relevance: str  # 답변의 문서에 대한 관련성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노드와 엣지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 개념\n",
    "\n",
    "- GraphState(상태 저장 그래프): LangGraph는 그래프의 각 노드가 계산의 단계를 나타내며, 그래프는 계산이 진행됨에 따라 전달되고 업데이트되는 상태를 유지하는 상태 저장 그래프 개념을 중심으로 작동합니다.\n",
    "- Node(노드): 노드는 LangGraph의 구성 요소입니다. 각 노드는 함수 또는 계산 단계를 나타냅니다. 입력 처리, 의사 결정, 외부 API와의 상호 작용 등 특정 작업을 수행하도록 노드를 정의할 수 있습니다.\n",
    "- Edge(엣지): 에지는 그래프에서 노드를 연결하여 계산의 흐름을 정의합니다. LangGraph는 조건부 에지를 지원하므로 그래프의 현재 상태에 따라 실행할 다음 노드를 동적으로 결정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notGrounded'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rag.utils import format_docs\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "# 업스테이지 문서 관련성 체크 기능을 설정합니다. https://upstage.ai\n",
    "upstage_ground_checker = UpstageGroundednessCheck()\n",
    "\n",
    "# 업스테이지 문서 관련성 체크를 실행합니다.\n",
    "upstage_ground_checker.run(\n",
    "    {\n",
    "        \"context\": format_docs(\n",
    "            pdf_retriever.invoke(\"삼성전자가 개발한 생성AI 의 이름은\")\n",
    "        ),\n",
    "        \"answer\": \"삼성전자가 개발한 생성AI 의 이름은 `빅스비 AI` 입니다.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # Question 에 대한 문서 검색을 retriever 로 수행합니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(state[\"question\"])\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=format_docs(retrieved_docs))\n",
    "\n",
    "\n",
    "# Chain을 사용하여 답변을 생성합니다.\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    return GraphState(\n",
    "        answer=pdf_chain.invoke(\n",
    "            {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # Question 에 대한 문서 검색을 retriever 로 수행합니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(state[\"question\"])\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=format_docs(retrieved_docs))\n",
    "\n",
    "\n",
    "# Chain을 사용하여 답변을 생성합니다.\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    return GraphState(\n",
    "        answer=pdf_chain.invoke(\n",
    "            {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "        ),\n",
    "        context=state[\"context\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# 테스트용 더미 답변 생성 함수\n",
    "def fake_llm_answer(state: GraphState) -> GraphState:\n",
    "    return GraphState(\n",
    "        answer=\"삼성전자가 개발한 생성AI 의 이름은 `빅스비 AI` 입니다.\",\n",
    "        context=state[\"context\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# 관련성 체크를 실행합니다.\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    # 관련성 체크를 실행합니다. 결과: grounded, notGrounded, notSure\n",
    "    response = upstage_ground_checker.run(\n",
    "        {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
    "    )\n",
    "    return GraphState(\n",
    "        relevance=response,\n",
    "        context=state[\"context\"],\n",
    "        answer=state[\"answer\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# 관련성 체크 결과를 반환합니다.\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    if state[\"relevance\"] == \"grounded\":\n",
    "        return \"관련성 O\"\n",
    "    elif state[\"relevance\"] == \"notGrounded\":\n",
    "        return \"관련성 X\"\n",
    "    elif state[\"relevance\"] == \"notSure\":\n",
    "        return \"확인불가\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드들을 정의합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve_document)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"llm_answer\", llm_answer)  # 정보 검색 노드를 추가합니다.\n",
    "\n",
    "# 테스트용 fake llm 을 추가합니다.\n",
    "# workflow.add_node(\"llm_answer\", fake_llm_answer)  # 정보 검색 노드를 추가합니다.\n",
    "\n",
    "\n",
    "workflow.add_node(\n",
    "    \"relevance_check\", relevance_check\n",
    ")  # 답변의 문서에 대한 관련성 체크 노드를 추가합니다.\n",
    "\n",
    "# 각 노드들을 연결합니다.\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 -> 관련성 체크\n",
    "\n",
    "# 조건부 엣지를 추가합니다.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"관련성 O\": END,  # 관련성이 있으면 종료합니다.\n",
    "        \"관련성 X\": \"retrieve\",  # 관련성이 없으면 다시 답변을 생성합니다.\n",
    "        \"확인불가\": \"retrieve\",  # 관련성 체크 결과가 모호하다면 다시 답변을 생성합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "# 시작점을 설정합니다.\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 기록을 위한 메모리 저장소를 설정합니다.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프를 컴파일합니다.\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    "    )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "except:\n",
    "    # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=13, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"삼성전자가 개발한 생성형 AI의 이름은?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "# 출력 결과를 확인합니다.\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])\n",
    "# RateLimitError 발생 - API 사용 한도 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[NODE] retrieve'\n",
      "('<context> <document><content>자 왈 개 유 부 지 이 작 지 자 아 무 시 야\\n'\n",
      " '子曰 蓋有不知而作之者 我無是也\\n'\n",
      " '다 문 택 기 선 자 이 종 지 다 견 이 식 지 지 지 차 야\\n'\n",
      " '多聞 擇其善者而從之 多見而識之 知之次也\\n'\n",
      " '공자가 말했다. 제대로 알지도 못하면서 새로운 것을 창작하려는 사람이 있\\n'\n",
      " '으나 나는 그렇지 않다. 나는 우선 많은 것을 들은 다음 그중 취해도 좋은 것\\n'\n",
      " '을 가려내어 본받는다. 또한 많이 본 다음 그중에서 내가 취해도 좋을 것을\\n'\n",
      " '가려내어 기억해둔다. 이것이 바로 ‘안다’는 것이며, 나면서부터 아는 것의\\n'\n",
      " '다음이다. _술이(述而) 27\\n'\n",
      " '※ 여기서 공자가 말한 ‘안다’는 것은 크게 세 가지로 나눌 수 있다. 첫 번째는 나면서\\n'\n",
      " '부터 아는 것(생이지지, 生而知之), 즉 배우지 않고서도 스스로 깨우치는 것을 말하는\\n'\n",
      " '데 흔히 천재들을 여기에 비한다. 그다음이 배워서 아는 것(학이지지, 學而知之)이고,\\n'\n",
      " '마지막이 고생한 끝에 알게 되는 것(곤이지지, 困而知之)이다. 어떤 경우이건 알고 '\n",
      " '난</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 (미리내공방) '\n",
      " '.pdf</source><page>82</page></document>\\n'\n",
      " '<document><content>누구나 한번쯤\\n'\n",
      " '읽어야 할 사서삼경\\n'\n",
      " '1판 1쇄 인쇄2 018년 7월 6일\\n'\n",
      " '1판 1쇄 발행 2018년 7월 13일\\n'\n",
      " '엮은이 | 미리내공방\\n'\n",
      " '펴낸이 | 최윤하\\n'\n",
      " '펴낸곳 | 정민미디어\\n'\n",
      " '주 소 | (151-834) 서울시 관악구 행운동 1666-45, F\\n'\n",
      " '전 화 | 02-888-0991\\n'\n",
      " '팩 스 | 02-871-0995\\n'\n",
      " '이메일 | pceo@daum.net\\n'\n",
      " '홈페이지 | www.hyuneum.com\\n'\n",
      " '편 집 | 미토스\\n'\n",
      " '표지디자인 | 김윤남\\n'\n",
      " '본문디자인 | 디자인 [연;우]\\n'\n",
      " 'ⓒ 정민미디어\\n'\n",
      " 'ISBN 979-11-86276-57-0 (03820)\\n'\n",
      " '※ 잘못 만들어진 책은 구입처에서 교환 가능합니다.</content><source>../12-RAG/data/1568)누구나 한번쯤 '\n",
      " '읽어야 할 사서삼경 (미리내공방) .pdf</source><page>353</page></document>\\n'\n",
      " '<document><content>이제 수도로 돌아가면 뭇사람이 우러러볼 것이네\\n'\n",
      " '수도에서 온 저 사람 삿갓에 검은 관이 잘 어울리는구나\\n'\n",
      " '저 군자의 따님은 새카만 머리카락이 삼단 같구나\\n'\n",
      " '이제 수도로 돌아가면 볼 수 없으니 쓸쓸한 내 마음 달랠 길 없구나\\n'\n",
      " '수도에서 온 저 사람 옥구슬로 귀막이하고\\n'\n",
      " '군자의 따님들은 윤씨 댁과 길씨 댁 규수라네\\n'\n",
      " '이제 수도로 돌아가면 볼 수 없으니 내 마음 서러워지네\\n'\n",
      " '수도에서 온 저 사람 검은 띠를 늘어뜨리고\\n'\n",
      " '군자의 따님들은 전갈 꼬리처럼 머리를 틀어 올렸네\\n'\n",
      " '이제 수도로 돌아가면 볼 수 없으니 그 뒤를 따라가고 싶네\\n'\n",
      " '일부러 늘어뜨린 게 아니라 띠가 길어서 저절로 늘어졌고\\n'\n",
      " '일부러 틀어 올린 게 아니라 머리카락이 바람에 날려 올라간 것이네\\n'\n",
      " '이제 수도로 돌아가면 볼 수 없구나\\n'\n",
      " '가슴은 왜 이리 아픈 걸까\\n'\n",
      " '_소아 어조지십 도인사(小雅 魚藻之什 都人士)\\n'\n",
      " '※ 시골 사람이 수도에서 내려온 사람들을 보고 부러워하는 장면을 노래했다.\\n'\n",
      " '황 의 상 제 임 하 유 혁 감 관 사 방\\n'\n",
      " '皇矣上帝 临下有赫 监觀四方</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 '\n",
      " '(미리내공방) .pdf</source><page>349</page></document>\\n'\n",
      " '<document><content>괘의 기본은 강효剛爻·양효陽爻, 유효柔爻·음효陰爻다. 이 중\\n'\n",
      " '강효와 유효 부호는 남녀의 생식기를 상징한다고 하는 설도\\n'\n",
      " '있으나 분명치는 않다. 다만, 서로 반대되는 성질을 상징한다\\n'\n",
      " '는 것만큼은 확실하다.\\n'\n",
      " '이 두 부호를 하나씩 더 사용해서 두 개의 결합을 만들어내면\\n'\n",
      " '네 가지의 변화가 생기고, 여기에 하나를 더 보태 세 개씩 만들\\n'\n",
      " '면 여덟 가지 변화가 얻어진다. 이것이 바로 8괘다.\\n'\n",
      " '8괘에 자연현상을 적용한 것이 상象이다. 상은 쉽게 말해 자연\\n'\n",
      " '의 상징을 뜻하는데, 이 8괘의 상이 역의 기본이다.\\n'\n",
      " '8괘의 명칭과 그에 따른 상은 다음과 같다.\\n'\n",
      " '-건乾, 하늘天\\n'\n",
      " '-곤坤, 땅地\\n'\n",
      " '-진震, 우레雷\\n'\n",
      " '-손巽, 바람風\\n'\n",
      " '-감坎, 물水\\n'\n",
      " '-이離, 불火\\n'\n",
      " '-간艮, 산山\\n'\n",
      " '-태兌, 못澤\\n'\n",
      " '294</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 (미리내공방) '\n",
      " '.pdf</source><page>295</page></document>\\n'\n",
      " '<document><content>상 란 기 평 기 안 차 녕 수 유 형 제 불 여 우 생\\n'\n",
      " '喪亂旣平 旣安且寧 雖有兄弟 不如友生\\n'\n",
      " '빈 이 변 두 음 주 지 어 형 제 기 구 화 락 차 유\\n'\n",
      " '儐爾籩豆 飮酒之飫 兄弟旣具 和樂且孺\\n'\n",
      " '처 자 호 합 여 고 슬 금 형 제 기 흡 화 락 차 담\\n'\n",
      " '妻子好合 如鼓瑟琴 兄弟旣翕 和樂且湛\\n'\n",
      " '의 이 실 가 낙 이 처 탕 시 구 시 도 단 기 연 호\\n'\n",
      " '宜爾室家 樂爾妻帑 是究是圖 亶其然乎\\n'\n",
      " '산앵두꽃 곱게 피어 울긋불긋하네\\n'\n",
      " '이 세상 누구보다도 형제가 제일이라네\\n'\n",
      " '죽을 고비에서도 형제는 서로 생각하고\\n'\n",
      " '송장 깔린 전쟁터에서 형제는 찾아가네\\n'\n",
      " '들판의 할미새가 시샘할 만큼 형제는 서로 돕네\\n'\n",
      " '좋은 친구 있다 해도 그저 하소연이나 할 상대라네\\n'\n",
      " '형제는 집안에서 싸워도 밖에서는 흉보일까 함께 막네\\n'\n",
      " '아무리 좋은 벗이 있다 해도 도울 일은 별로 없네\\n'\n",
      " '세상 난리가 끝나고 태평성대를 누릴 때는\\n'\n",
      " '형제의 고마움을 잊고 친구와 가까워지기도 하지\\n'\n",
      " '그러나 좋은 안주에 술을 마실 때\\n'\n",
      " '형제가 한자리에 모이면 어린아이처럼 즐거워진다네</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 '\n",
      " '할 사서삼경 (미리내공방) .pdf</source><page>341</page></document>')\n",
      "'=============================='\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# 출력된 결과에서 키와 값을 순회합니다.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;66;03m# 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m             pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[NODE] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\__init__.py:966\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m    965\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 966\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1367\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step, timeout_exc_cls)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1366\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\executor.py:60\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\retry.py:25\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     23\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:2873\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2869\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   2870\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2871\u001b[0m )\n\u001b[0;32m   2872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mllm_answer\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm_answer\u001b[39m(state: GraphState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GraphState:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GraphState(\n\u001b[1;32m---> 12\u001b[0m         answer\u001b[38;5;241m=\u001b[39m\u001b[43mpdf_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     15\u001b[0m         context\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     16\u001b[0m         question\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2873\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2874\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2875\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:274\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    271\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    273\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    275\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    276\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    277\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    278\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    279\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    280\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    282\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    283\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    284\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:714\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    708\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    713\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    570\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    572\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    573\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    575\u001b[0m ]\n\u001b[0;32m    576\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:561\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    562\u001b[0m                 m,\n\u001b[0;32m    563\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    564\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    565\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    566\u001b[0m             )\n\u001b[0;32m    567\u001b[0m         )\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:793\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 793\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    794\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:601\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    602\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\resources\\chat\\completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1054\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=13, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "# GraphState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(question=\"삼성전자가 개발한 생성형 AI의 이름은?\")\n",
    "\n",
    "# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "try:\n",
    "    for output in app.stream(inputs, config=config):\n",
    "        # 출력된 결과에서 키와 값을 순회합니다.\n",
    "        for key, value in output.items():\n",
    "            # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "            pprint.pprint(f\"[NODE] {key}\")\n",
    "            for k, v in value.items():\n",
    "                pprint.pprint(f\"<{k}> {v}\")\n",
    "            pprint.pprint(\"===\" * 10)\n",
    "            # 출력 값을 예쁘게 출력합니다.\n",
    "            # pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "except GraphRecursionError as e:\n",
    "    pprint.pprint(f\"Recursion limit reached: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question: \\t\", output[\"relevance_check\"][\"question\"])\n",
    "print(\"Answer: \\t\", output[\"relevance_check\"][\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance_check\"][\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
