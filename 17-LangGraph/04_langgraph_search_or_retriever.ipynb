{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 부족한 정보를 검색하여 Context 보강"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "절차\n",
    "\n",
    "- 전통적인 RAG 를 수행\n",
    "- 검색된 문서에 답변에 필요한 정보가 부족한 경우 -> “웹 검색”을 위한 쿼리 재작성\n",
    "- “웹 검색” 으로 보충된 정보로 답변 도출 시도\n",
    "- 새로운 답변으로 관련성 체크 후 재조정/종료 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LANGGRAPH\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LANGGRAPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "pdf = PDFRetrievalChain([\"../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 (미리내공방) .pdf\"]).create_chain()\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# GraphState 상태를 저장하는 용도로 사용합니다.\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # 질문\n",
    "    context: str  # 문서의 검색 결과\n",
    "    answer: str  # 답변\n",
    "    relevance: str  # 답변의 문서에 대한 관련성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노드와 엣지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 agentic RAG 그래프를 다음과 같이 구성할 수 있습니다:\n",
    "\n",
    "- 상태는 메시지의 집합입니다\n",
    "- 각 노드는 상태를 업데이트(추가)합니다\n",
    "- 조건부 엣지는 다음에 방문할 노드를 결정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from rag.utils import format_docs, format_searched_docs\n",
    "\n",
    "# 업스테이지 문서 관련성 체크 기능을 설정합니다. https://upstage.ai\n",
    "upstage_ground_checker = UpstageGroundednessCheck()\n",
    "\n",
    "\n",
    "# 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(state[\"question\"])\n",
    "\n",
    "    # 검색된 문서를 형식화합니다.\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=retrieved_docs)\n",
    "\n",
    "\n",
    "# LLM을 사용하여 답변을 생성합니다.\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # 체인을 호출하여 답변을 생성합니다.\n",
    "    response = pdf_chain.invoke({\"question\": question, \"context\": context})\n",
    "\n",
    "    return GraphState(answer=response)\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    question = state[\"question\"]\n",
    "    answer = state[\"answer\"]\n",
    "    context = state[\"context\"]\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a professional prompt rewriter. Your task is to generate the question in order to get additional information that is now shown in the context.\"\n",
    "                \"Your generated question will be searched on the web to find relevant information.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Rewrite the question to get additional information to get the answer.\"\n",
    "                \"\\n\\nHere is the initial question:\\n ------- \\n{question}\\n ------- \\n\"\n",
    "                \"\\n\\nHere is the initial context:\\n ------- \\n{context}\\n ------- \\n\"\n",
    "                \"\\n\\nHere is the initial answer to the question:\\n ------- \\n{answer}\\n ------- \\n\"\n",
    "                \"\\n\\nFormulate an improved question in Korean:\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Question rewriting model\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    response = chain.invoke(\n",
    "        {\"question\": question, \"answer\": answer, \"context\": context}\n",
    "    )\n",
    "    return GraphState(question=response)\n",
    "\n",
    "\n",
    "def search_on_web(state: GraphState) -> GraphState:\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    search_tool = TavilySearchResults(max_results=5)\n",
    "    search_result = search_tool.invoke({\"query\": state[\"question\"]})\n",
    "\n",
    "    # 검색된 문서를 형식화합니다.\n",
    "    search_result = format_searched_docs(search_result)\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(\n",
    "        context=search_result,\n",
    "    )\n",
    "\n",
    "\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    print(\"relevance_check\", state)\n",
    "    # 관련성 체크를 실행합니다. 결과: grounded, notGrounded, notSure\n",
    "    response = upstage_ground_checker.run(\n",
    "        {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
    "    )\n",
    "    return GraphState(\n",
    "        relevance=response, question=state[\"question\"], answer=state[\"answer\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    return state[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드들을 정의합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve_document)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"llm_answer\", llm_answer)  # 정보 검색 노드를 추가합니다.\n",
    "workflow.add_node(\n",
    "    \"relevance_check\", relevance_check\n",
    ")  # 답변의 문서에 대한 관련성 체크 노드를 추가합니다.\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 질문을 재작성하는 노드를 추가합니다.\n",
    "workflow.add_node(\"search_on_web\", search_on_web)  # 웹 검색 노드를 추가합니다.\n",
    "\n",
    "# 각 노드들을 연결합니다.\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 -> 관련성 체크\n",
    "workflow.add_edge(\"rewrite\", \"search_on_web\")  # 재작성 -> 관련성 체크\n",
    "workflow.add_edge(\"search_on_web\", \"llm_answer\")  # 웹 검색 -> 답변\n",
    "\n",
    "\n",
    "# 조건부 엣지를 추가합니다.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"grounded\": END,  # 관련성이 있으면 종료합니다.\n",
    "        \"notGrounded\": \"rewrite\",  # 관련성이 없으면 다시 답변을 생성합니다.\n",
    "        \"notSure\": \"rewrite\",  # 관련성 체크 결과가 모호하다면 다시 답변을 생성합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    "    )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "except:\n",
    "    # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'context': '<document><content>차\\n'\n",
      "             '례\\n'\n",
      "             '머리말 … 5\\n'\n",
      "             '論\\n'\n",
      "             '논어란? …12\\n'\n",
      "             '語\\n'\n",
      "             '성인 공자 16 | 평생 학문에 뜻을 두고 18 | 무덤만이 사람이 쉴 곳 20 | 군자는 고\\n'\n",
      "             '루 나누어준다 24 | 임금 자리도 마다한 사람 27 | 사냥하면서도 인을 생각하라\\n'\n",
      "             '29 | 공자가 가장 아낀 제자, 안회 31 | 보배로운 그릇 같은 존재 33 | 배우는 사람\\n'\n",
      "             '의 마음가짐 35 | 팔일무 사건 38 | 예로써 다스리는 나라 40 | 공자의 식생활 44 |\\n'\n",
      "             '공자의 의생활 48 | 공자가 두려워하고 멀리한 것들 50 | 인에 대하여 53 | 군자에\\n'\n",
      "             '대하여 57 | 곧은 마음의 본보기, 백이와 숙제 61 | 공자의 일상생활 64 | 《논어》\\n'\n",
      "             '의 명구절 66\\n'\n",
      "             '孟\\n'\n",
      "             '맹자란? …98\\n'\n",
      "             '子\\n'\n",
      "             '오십보백보 102 | 인자무적 106 | 40리나 되는 거대한 함정 108 | 성선설에 대하\\n'\n",
      "             '여 112 | 나라를 잘못 다스린 죄 115 | 인으로써 구해야 정도 117 | 군자의 '\n",
      "             '합리적</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 '\n",
      "             '(미리내공방) .pdf</source><page>9</page></document>\\n'\n",
      "             '<document><content>전10장: 치국평천하治國平天下\\n'\n",
      "             '그밖에\\n'\n",
      "             '주자에 따르면 《대학》은 인간을 교육하는 도를 해설한 것이다. 이\\n'\n",
      "             '는 사서四書 중 가장 중요한 것으로, 이 책을 통달하면 다른 경전의\\n'\n",
      "             '문구는 《대학》을 기본으로 한 풀이로밖에 생각되지 않는다고 했다.\\n'\n",
      "             '《대학》에 대한 해석은 다양한데, 형이상학적인 문구 때문에 다소\\n'\n",
      "             '이해하기 힘든 면도 있다.\\n'\n",
      "             '165</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 '\n",
      "             '(미리내공방) .pdf</source><page>166</page></document>\\n'\n",
      "             '<document><content>자 왈 빈 이 무 원 난 부 이 무 교 이\\n'\n",
      "             '子曰 貧而無怨難 富而無驕易\\n'\n",
      "             '공자가 말했다. 가난하면서 원망하지 않기는 어려운 일이고 부자이면서 교\\n'\n",
      "             '만하지 않기는 쉬운 일이다. _헌문(憲問) 11\\n'\n",
      "             '자 왈 군 자 치 기 언 이 과 기 행\\n'\n",
      "             '子曰 君子恥其言而過其行\\n'\n",
      "             '공자가 말했다. 군자는 자기가 한 말이 자기가 한 행동보다 지나치게 되는\\n'\n",
      "             '것을 부끄러워한다. _헌문(憲問) 29\\n'\n",
      "             '자 왈 상 호 례 즉 민 이 사 야\\n'\n",
      "             '子曰 上好禮 則民易使也\\n'\n",
      "             '공자가 말했다. 윗사람이 예를 좋아하면 아랫사람을 부리기가 쉽다. _헌문(憲問) 44\\n'\n",
      "             '자 왈 가 여 언 이 불 여 지 언\\n'\n",
      "             '子曰 可與言 而不與之言\\n'\n",
      "             '실 인 불 가 여 언 이 여 지 언\\n'\n",
      "             '失人 不可與言 而與之言\\n'\n",
      "             '실 언 지 자 불 실 인 역 불 실 언\\n'\n",
      "             '失言 知者不失人 亦不失言\\n'\n",
      "             '공자가 말했다. 더불어 말할 만한 사람인데도 말하지 않으면 사람을 잃는 것\\n'\n",
      "             '이고, 더불어 말할 만한 사람이 아닌데도 말하면 말을 잃는 것이다. '\n",
      "             '지혜로</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 '\n",
      "             '(미리내공방) .pdf</source><page>91</page></document>\\n'\n",
      "             '<document><content>넷째, 행동을 할 때는 공손하게 할 것. 다섯째, 말할 때는 충실하게 할 것. '\n",
      "             '여\\n'\n",
      "             '섯째, 일을 할 때는 신중하게 할 것. 일곱째, 의심이 생길 때는 물어볼 것. 여\\n'\n",
      "             '덟째, 분할 때는 뒤에 닥쳐올 재난을 생각할 것. 아홉째, 이득이 생겼을 때는\\n'\n",
      "             '과연 의로운 것인가를 생각할 것. _계씨(季氏) 10\\n'\n",
      "             '자 왈 성 상 근 야 습 상 원 야\\n'\n",
      "             '子曰 性相近也 習相遠也\\n'\n",
      "             '공자가 말했다. 사람이 타고나는 천성은 서로 비슷하지만 점점 시간이 흐르\\n'\n",
      "             '면서 습관에 의해 서로 멀어진다. _양화(陽貨) 2\\n'\n",
      "             '자 왈 소 자 하 막 학 부 시 시 가 이 흥 가 이 관 가 이 군 가 이 원\\n'\n",
      "             '子曰 小子 何莫學夫詩 詩 可以興 可以觀 可以群 可以怨\\n'\n",
      "             '이 지 사 부 원 지 사 군 다 식 어 조 수 초 목 지 명\\n'\n",
      "             '邇之事父 遠之事君 多識於鳥獸草木之名\\n'\n",
      "             '공자가 제자들에게 말했다. 너희는 왜 시경을 공부하지 않는지 모르겠구나.\\n'\n",
      "             '시는 감흥을 일으키고 사물을 잘 살필 수 있도록 하며 여러 사람과 잘 '\n",
      "             '어울</content><source>../12-RAG/data/1568)누구나 한번쯤 읽어야 할 사서삼경 '\n",
      "             '(미리내공방) .pdf</source><page>95</page></document>\\n'\n",
      "             '<document><content>공 왈 선 재 신 여 군 불 군 신 불 신 부 불 부 자 부 자\\n'\n",
      "             '公曰 善哉 信如君不君 臣不臣 父不父 子不子\\n'\n",
      "             '수 유 속 오 득 이 식 저\\n'\n",
      "             '雖有粟 吾得而食諸\\n'\n",
      "             '제나라 경공이 공자에게 정치란 무엇이냐고 묻자 공자가 대답했다.\\n'\n",
      "             '“임금은 임금다워야 하고, 신하는 신하다워야 하며, 어버이는 어버이다워야\\n'\n",
      "             '하고, 자식은 자식다워야 합니다.”\\n'\n",
      "             '경공이 감탄하며 말했다.\\n'\n",
      "             '“참으로 좋은 말씀입니다. 진실로 임금이 임금의 임무를 못하고, 신하가 신\\n'\n",
      "             '하의 임무를 못하며, 어버이가 어버이의 노릇을 못하고, 자식이 자식의 할\\n'\n",
      "             '바를 다하지 못한다면, 비록 창고에 곡식이 넘쳐난들 내 어찌 그것을 얻어먹\\n'\n",
      "             '을 수가 있겠습니까?” _안연(顔淵) 11\\n'\n",
      "             '계 강 자 문 정 어 공 자 왈 여 살 무 도 이 취 유 도 하 여\\n'\n",
      "             '季康子問政於孔子曰 如殺無道 以就有道 何如\\n'\n",
      "             '공 자 대 왈 자 위 정 언 용 살 자 욕 선 이 민 선 의 군 자 지 덕 풍\\n'\n",
      "             '孔子對曰 子爲政 焉用殺 子欲善 而民善矣 君子之德風\\n'\n",
      "             '소 인 지 덕 초 초 상 지 풍 필 언</content><source>../12-RAG/data/1568)누구나 '\n",
      "             '한번쯤 읽어야 할 사서삼경 (미리내공방) .pdf</source><page>89</page></document>'}\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# 출력된 결과에서 키와 값을 순회합니다.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;66;03m# 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m             pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput from node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\__init__.py:966\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m    965\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 966\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1367\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step, timeout_exc_cls)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1366\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\executor.py:60\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\pregel\\retry.py:25\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     23\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:2873\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2869\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   2870\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2871\u001b[0m )\n\u001b[0;32m   2872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langgraph\\utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m, in \u001b[0;36mllm_answer\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     27\u001b[0m context \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 체인을 호출하여 답변을 생성합니다.\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GraphState(answer\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2873\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2874\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2875\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:274\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    271\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    273\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    275\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    276\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    277\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    278\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    279\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    280\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    282\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    283\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    284\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:714\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    708\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    713\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    570\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    572\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    573\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    575\u001b[0m ]\n\u001b[0;32m    576\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:561\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    562\u001b[0m                 m,\n\u001b[0;32m    563\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    564\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    565\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    566\u001b[0m             )\n\u001b[0;32m    567\u001b[0m         )\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:793\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 793\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    794\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:601\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    602\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\resources\\chat\\completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anHye\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1054\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=12, configurable={\"thread_id\": \"CORRECTIVE-SEARCH-RAG\"}\n",
    ")\n",
    "\n",
    "# AgentState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(\n",
    "    question=\"논어에서 공자가 한 말중 가장 중요한 부분은 무엇입니까\"\n",
    ")\n",
    "\n",
    "# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "try:\n",
    "    for output in app.stream(inputs, config=config):\n",
    "        # 출력된 결과에서 키와 값을 순회합니다.\n",
    "        for key, value in output.items():\n",
    "            # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(\"---\")\n",
    "            # 출력 값을 예쁘게 출력합니다.\n",
    "            pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        # 각 출력 사이에 구분선을 추가합니다.\n",
    "        pprint.pprint(\"\\n---\\n\")\n",
    "except GraphRecursionError as e:\n",
    "    pprint.pprint(f\"Recursion limit reached: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"relevance_check\"][\"question\"])\n",
    "print(output[\"relevance_check\"][\"answer\"])\n",
    "print(output[\"relevance_check\"][\"relevance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
