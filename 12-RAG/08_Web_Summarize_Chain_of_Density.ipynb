{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\"https://teddylee777.github.io/data-science/optuna/\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "\n",
    "# Get this prompt template\n",
    "prompt = hub.pull(\"lawwu/chain_of_density\")\n",
    "\n",
    "# The chat model output is a JSON list of dicts, with SimpleJsonOutputParser\n",
    "# we can convert it o a dict, and it suppors streaming.\n",
    "json_parser = SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"ARTICLE\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n",
    "    | json_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Missing_Entities': 'Optuna',\n",
       "  'Denser_Summary': \"This article discusses Optuna, a hyperparameter optimization framework. Optuna is a powerful tool for optimizing machine learning models. It provides various methods for suggesting hyperparameters, such as suggest_categorical, suggest_int, and suggest_float. With Optuna, you can easily optimize your model's performance by finding the best hyperparameters.\"},\n",
       " {'Missing_Entities': 'study',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization framework. Optuna provides a study object that allows you to optimize your model by finding the best hyperparameters. You can create a study and use the optimize() method to search for the optimal hyperparameters. The study keeps track of the best parameters found so far and allows you to access them using the best_params attribute.'},\n",
       " {'Missing_Entities': 'objective function',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization framework. Optuna allows you to define an objective function that evaluates the performance of your model. The objective function takes the trial object as an argument and suggests hyperparameters using the trial.suggest_ methods. By minimizing or maximizing the objective function, Optuna finds the best hyperparameters for your model.'},\n",
       " {'Missing_Entities': 'RandomForestRegressor',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization framework. Optuna can be used to optimize hyperparameters for various machine learning models, including RandomForestRegressor. You can define an objective function that evaluates the performance of the RandomForestRegressor model using Optuna. Optuna will search for the best hyperparameters for the RandomForestRegressor model to improve its performance.'},\n",
       " {'Missing_Entities': 'KFold',\n",
       "  'Denser_Summary': \"This article discusses Optuna, a hyperparameter optimization framework. Optuna can be used in combination with KFold cross-validation to optimize hyperparameters for machine learning models. By using KFold, you can split your data into multiple folds and evaluate the model's performance on each fold. Optuna will search for the best hyperparameters that result in the best overall performance across all folds.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"\",\n",
      "        \"Denser_Summary\": \"이 기사는 최근 스포츠 세계에서 발생한 중요한 사건에 대해 다루고 있습니다. 특히, 여러 스포츠 분야에서의 주요 경기 결과와 그에 따른 선수들의 성과, 팀의 순위 변동 등을 상세히 설명하고 있습니다. 또한, 이러한 경기들이 앞으로 스포츠계에 미칠 영향에 대해서도 분석하고 있으며, 특정 선수들의 인터뷰 내용을 인용하여 그들의 생각과 감정을 전달하고 있습니다. 이와 함께, 경기 일정, 선수들의 부상 소식, 이적 소식 등도 포함되어 있어 스포츠 팬들에게 유용한 정보를 제공하고 있습니다. 전반적으로, 이 기사는 스포츠에 대한 광범위한 정보를 제공하며, 독자들이 최신 스포츠 동향을 이해하는 데 도움을 주고자 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"경기 결과; 선수 인터뷰\",\n",
      "        \"Denser_Summary\": \"이 기사는 다양한 스포츠 분야에서의 경기 결과와 선수들의 인터뷰 내용을 포함하여 스포츠 세계의 최신 동향을 다룹니다. 주요 경기의 결과와 선수들의 성과, 팀 순위 변동을 상세히 분석하고, 선수들의 인터뷰를 통해 그들의 생각과 감정을 전달합니다. 또한, 경기 일정, 부상 및 이적 소식 등을 포함하여 스포츠 팬들에게 유용한 정보를 제공합니다. 이 기사는 스포츠에 대한 광범위한 정보를 제공하며, 독자들이 최신 스포츠 동향을 이해하는 데 도움을 주는 것을 목표로 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"팀 순위 변동; 부상 및 이적 소식\",\n",
      "        \"Denser_Summary\": \"이 기사는 다양한 스포츠 분야의 경기 결과, 선수 인터뷰, 팀 순위 변동, 부상 및 이적 소식을 포함하여 최신 스포츠 동향을 다룹니다. 경기 결과와 선수들의 성과 분석, 선수들의 생각과 감정을 담은 인터뷰, 팀 순위의 변동, 선수들의 부상과 이적 소식까지, 스포츠 팬들에게 유용한 정보를 광범위하게 제공합니다. 이를 통해 독자들은 최신 스포츠 동향을 이해하고, 스포츠 세계의 변화를 파악하는 데 도움을 받을 수 있습니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"경기 일정\",\n",
      "        \"Denser_Summary\": \"이 기사는 경기 결과, 선수 인터뷰, 팀 순위 변동, 부상 및 이적 소식, 경기 일정을 포함한 최신 스포츠 동향을 다룹니다. 선수들의 성과와 생각, 팀 순위의 변화, 선수들의 부상과 이적 정보, 그리고 앞으로의 경기 일정까지, 스포츠 팬들에게 필요한 모든 정보를 제공하며, 독자들이 스포츠 세계의 최신 동향을 파악하는 데 도움을 줍니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"스포츠 팬들에게 필요한 정보\",\n",
      "        \"Denser_Summary\": \"이 기사는 경기 결과, 선수 인터뷰, 팀 순위 변동, 부상 및 이적 소식, 경기 일정 등 스포츠 팬들에게 필요한 정보를 포함한 최신 스포츠 동향을 다룹니다. 선수들의 성과와 생각, 팀 순위의 변화, 선수들의 부상과 이적 정보, 그리고 앞으로의 경기 일정까지 모두 포함하여, 독자들이 스포츠 세계의 최신 동향을 파악하는 데 도움을 줍니다.\"\n",
      "    }\n",
      "]\n",
      "```이 기사는 경기 결과, 선수 인터뷰, 팀 순위 변동, 부상 및 이적 소식, 경기 일정 등 스포츠 팬들에게 필요한 정보를 포함한 최신 스포츠 동향을 다룹니다. 선수들의 성과와 생각, 팀 순위의 변화, 선수들의 부상과 이적 정보, 그리고 앞으로의 경기 일정까지 모두 포함하여, 독자들이 스포츠 세계의 최신 동향을 파악하는 데 도움을 줍니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import json\n",
    "\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\n",
    "    \"https://m.sports.naver.com/esports/article/311/0001752220?sid3=79b\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "# Load the prompt\n",
    "# prompt = hub.pull(\"langchain-ai/chain-of-density:4f55305e\")\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 5 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (50 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the chain, including\n",
    "chain = (\n",
    "    prompt\n",
    "    | ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    )\n",
    "    | JsonOutputParser()\n",
    "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"ARTICLE\": content})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
